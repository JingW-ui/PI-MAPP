#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced UI Main - ä¸»ç•Œé¢å®ç°
åŒ…å«å®Œæ•´çš„å¢å¼ºUIç•Œé¢
"""

import sys
import os
import cv2
import time
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple

from PySide6.QtWidgets import *
from PySide6.QtCore import *
from PySide6.QtGui import *
import numpy as np

# !/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Components - å¢å¼ºç»„ä»¶æ¨¡å—
åŒ…å«æ‰¹é‡æ£€æµ‹ã€ç»“æœæ˜¾ç¤ºã€ç›‘æ§ç­‰ç»„ä»¶
"""
import sys
import threading

import cv2
import time
import numpy as np
from pathlib import Path
from datetime import datetime
from PySide6.QtWidgets import *
from PySide6.QtCore import *
from PySide6.QtGui import *
from ultralytics import YOLO

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Universal Object Detection System v2.0
ä¼˜åŒ–çš„é€šç”¨ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ - ä¸»ç¨‹åº

æ–°åŠŸèƒ½ç‰¹æ€§:
âœ¨ æ¸å˜UIæ ·å¼æ•ˆæœ
ğŸ“± ä¼˜åŒ–çš„å“åº”å¼å¸ƒå±€
ğŸ“Š å¢å¼ºçš„æ—¥å¿—æ˜¾ç¤ºï¼ˆç±»åˆ«è¯†åˆ«ä¿¡æ¯ï¼‰
ğŸ“ æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹ç›®å½•åŠ è½½
ğŸ“¹ å¤šæ‘„åƒå¤´æ”¯æŒå’Œé€‰æ‹©
ğŸ–¥ï¸ å®æ—¶ç›‘æ§é¡µé¢
ğŸ¨ ä¼˜åŒ–çš„å›¾æ ‡è®¾è®¡
âš¡ æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†
"""

import sys
import os
import cv2
import time
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple

from PySide6.QtWidgets import *
from PySide6.QtCore import *
from PySide6.QtGui import *
import numpy as np

try:
    from ultralytics import YOLO
except ImportError:
    print("é”™è¯¯: è¯·å®‰è£…ultralyticsåº“: pip install ultralytics")
    sys.exit(1)


class StyleManager:
    """æ ·å¼ç®¡ç†å™¨ - æä¾›æ¸å˜å’Œç°ä»£åŒ–UIæ ·å¼"""

    @staticmethod
    def get_main_stylesheet():
        return """
            QMainWindow {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                    stop:0 #f8f9fa, stop:1 #e9ecef);
            }

            QGroupBox {
                font-weight: bold;
                font-size: 12px;
                border: 2px solid rgba(52, 152, 219, 0.7);
                border-radius: 8px;
                margin-top: 1ex;
                padding-top: 15px;
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 rgba(255, 255, 255, 0.9), stop:1 rgba(245, 245, 245, 0.9));
            }

            QGroupBox::title {
                subcontrol-origin: margin;
                left: 15px;
                padding: 0 10px 0 10px;
                color: #2c3e50;
                font-size: 13px;
                font-weight: bold;
            }

            QPushButton {
                padding: 2px 8px;
                font-size: 12px;
                font-weight: bold;
                border: none;
                border-radius: 8px;
                color: white;
                min-width: 65px;
                min-height: 25px;
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #3498db, stop:1 #2980b9);
            }

            QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #5dade2, stop:1 #3498db);
                transform: translateY(-1px);
            }

            QPushButton:pressed {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #2980b9, stop:1 #1f618d);
            }

            QPushButton:disabled {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #bdc3c7, stop:1 #95a5a6);
                color: #7f8c8d;
            }

            QComboBox {
                padding: 2px 8px;
                border: 2px solid rgba(189, 195, 199, 0.5);
                border-radius: 8px;
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 white, stop:1 #f8f9fa);
                font-size: 12px;
                min-width: 150px;
                min-height: 25px;
            }

            QComboBox:focus {
                border-color: #3498db;
                background: white;
            }

            QProgressBar {
                border: 2px solid rgba(189, 195, 199, 0.5);
                border-radius: 8px;
                text-align: center;
                font-weight: bold;
                font-size: 11px;
                max-height: 20px;
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #ecf0f1, stop:1 #d5dbdb);
            }

            QProgressBar::chunk {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #2ecc71, stop:1 #27ae60);
                border-radius: 6px;
                margin: 1px;
            }

            QTextEdit {
                border: 2px solid rgba(189, 195, 199, 0.5);
                border-radius: 8px;
                background: rgba(255, 255, 255, 0.95);
                font-family: 'Consolas', 'Monaco', monospace;
                font-size: 11px;
                padding: 8px;
                selection-background-color: #3498db;
            }

            QSlider::groove:horizontal {
                border: 1px solid rgba(189, 195, 199, 0.5);
                height: 8px;
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #ecf0f1, stop:1 #bdc3c7);
                border-radius: 4px;
            }

            QSlider::handle:horizontal {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #3498db, stop:1 #2980b9);
                border: 2px solid #2980b9;
                width: 20px;
                height: 20px;
                margin: -8px 0;
                border-radius: 12px;
            }

            QSlider::handle:horizontal:hover {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #5dade2, stop:1 #3498db);
            }

            QSpinBox, QDoubleSpinBox {
                padding: 6px 10px;
                border: 2px solid rgba(189, 195, 199, 0.5);
                border-radius: 6px;
                background: white;
                min-width: 80px;
                font-size: 12px;
            }

            QTabWidget::pane {
                border: 2px solid rgba(189, 195, 199, 0.5);
                border-radius: 10px;
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 rgba(255, 255, 255, 0.95), stop:1 rgba(245, 245, 245, 0.95));
                margin-top: 5px;
            }

            QTabBar::tab {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #ecf0f1, stop:1 #bdc3c7);
                border: 2px solid rgba(189, 195, 199, 0.5);
                border-bottom: none;
                border-radius: 8px 8px 0 0;
                padding: 12px 25px;
                margin-right: 3px;
                font-weight: bold;
                font-size: 12px;
                color: #2c3e50;
            }

            QTabBar::tab:selected {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #3498db, stop:1 #2980b9);
                color: white;
                border-color: rgba(52, 152, 219, 0.7);
            }

            QTabBar::tab:hover:!selected {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #d5dbdb, stop:1 #bdc3c7);
            }

            QTableWidget {
                border: 2px solid rgba(189, 195, 199, 0.5);
                border-radius: 8px;
                background: white;
                gridline-color: rgba(189, 195, 199, 0.3);
                selection-background-color: rgba(52, 152, 219, 0.2);
                alternate-background-color: rgba(248, 249, 250, 0.5);
            }

            QTableWidget::item {
                padding: 8px;
                border: none;
            }

            QTableWidget::item:selected {
                background: rgba(52, 152, 219, 0.3);
                color: #2c3e50;
            }

            QHeaderView::section {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #34495e, stop:1 #2c3e50);
                color: white;
                padding: 8px;
                border: none;
                font-weight: bold;
            }

            QListWidget {
                border: 2px solid rgba(189, 195, 199, 0.5);
                border-radius: 8px;
                background: white;
                selection-background-color: rgba(52, 152, 219, 0.2);
            }

            QListWidget::item {
                padding: 8px;
                border-bottom: 1px solid rgba(189, 195, 199, 0.2);
            }

            QListWidget::item:selected {
                background: rgba(52, 152, 219, 0.3);
                color: #2c3e50;
            }

            QScrollBar:vertical {
                background: rgba(236, 240, 241, 0.5);
                width: 12px;
                border-radius: 6px;
            }

            QScrollBar::handle:vertical {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                    stop:0 #bdc3c7, stop:1 #95a5a6);
                border-radius: 6px;
                min-height: 20px;
            }

            QScrollBar::handle:vertical:hover {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                    stop:0 #95a5a6, stop:1 #7f8c8d);
            }
            #startBtn {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #10B981, stop:1 #059669);
            color: white;
            border: none;
            border-radius: 3px;  /* å‡å°åœ†è§’ */
            min-width: 10px;  /* å‡å°æœ€å°å®½åº¦ */
            min-height: 10px;  /* æ·»åŠ æœ€å°é«˜åº¦ */
            font-size: 8px;  /* å‡å°å­—ä½“å¤§å° */
        }
        #startBtn:hover {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #059669, stop:1 #047857);
        }

        #pauseBtn {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #F59E0B, stop:1 #D97706);
            color: white;
            border: none;
            border-radius: 3px;  /* å‡å°åœ†è§’ */
            min-width: 10px;  /* å‡å°æœ€å°å®½åº¦ */
            min-height: 10px;  /* æ·»åŠ æœ€å°é«˜åº¦ */
            font-size: 8px;  /* å‡å°å­—ä½“å¤§å° */
        }
        #pauseBtn:hover {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #D97706, stop:1 #B45309);
        }

        #stopBtn {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #EF4444, stop:1 #DC2626);
            color: white;
            border: none;
            border-radius: 3px;  /* å‡å°åœ†è§’ */
            min-width: 10px;  /* å‡å°æœ€å°å®½åº¦ */
            min-height: 10px;  /* æ·»åŠ æœ€å°é«˜åº¦ */
            font-size: 8px;  /* å‡å°å­—ä½“å¤§å° */
        }
        #stopBtn:hover {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #DC2626, stop:1 #B91C1C);
        }

        #monitorBtn {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #3B82F6, stop:1 #2563EB);
            color: white;
            border: none;
            border-radius: 3px;  /* å‡å°åœ†è§’ */
            min-width: 10px;  /* å‡å°æœ€å°å®½åº¦ */
            min-height: 10px;  /* æ·»åŠ æœ€å°é«˜åº¦ */
            font-size: 8px;  /* å‡å°å­—ä½“å¤§å° */
        }
        #monitorBtn:hover {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #2563EB, stop:1 #1D4ED8);
        }

        #clearBtn {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #94A3B8, stop:1 #64748B);
            color: white;
            border: none;
            border-radius: 3px;  /* å‡å°åœ†è§’ */
            min-width: 10px;  /* å‡å°æœ€å°å®½åº¦ */
            min-height: 10px;  /* æ·»åŠ æœ€å°é«˜åº¦ */
            font-size: 8px;  /* å‡å°å­—ä½“å¤§å° */
        }
        #clearBtn:hover {
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                                       stop:0 #64748B, stop:1 #475569);
        }
        """

    @staticmethod
    def get_image_label_style():
        return """
            border: 3px solid rgba(52, 152, 219, 0.3);
            background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                stop:0 rgba(248, 249, 250, 0.9), stop:1 rgba(233, 236, 239, 0.9));
            color: #7f8c8d;
            font-weight: bold;
            font-size: 14px;
            border-radius: 10px;
            padding: 15px;
        """

    @staticmethod
    def get_video_label_style():
        return """
            border: 1px solid rgba(52, 152, 219, 0.3);
            background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                stop:0 rgba(248, 249, 250, 0.9), stop:1 rgba(233, 236, 239, 0.9));
            color: #7f8c8d;
            font-weight: bold;
            font-size: 14px;
            border-radius: 10px;
        """


class CameraManager:
    """æ‘„åƒå¤´ç®¡ç†å™¨ - å¤„ç†å¤šæ‘„åƒå¤´æ£€æµ‹å’Œç®¡ç†"""

    def __init__(self):
        self.cameras = []
        self.scan_cameras()

    def scan_cameras(self):
        """æ‰«æå¯ç”¨æ‘„åƒå¤´"""
        self.cameras = []

        # æ£€æµ‹æ‘„åƒå¤´ï¼ˆæ£€æµ‹å‰8ä¸ªç´¢å¼•ï¼‰
        for i in range(8):  # æ‰©å±•åˆ°8ä¸ªæ‘„åƒå¤´æ£€æµ‹
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret and frame is not None:
                    # è·å–æ‘„åƒå¤´ä¿¡æ¯
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    fps = cap.get(cv2.CAP_PROP_FPS)

                    camera_info = {
                        'id': i,
                        'name': f"æ‘„åƒå¤´ {i}",
                        'resolution': f"{width}x{height}",
                        'fps': fps if fps > 0 else 30,
                        'available': True,
                        'cap': None  # ä¿ç•™æ‘„åƒå¤´å¯¹è±¡ä½ç½®
                    }
                    self.cameras.append(camera_info)
                cap.release()

        # å¦‚æœæ²¡æœ‰æ‘„åƒå¤´ï¼Œæ·»åŠ è™šæ‹Ÿæ‘„åƒå¤´ç”¨äºæµ‹è¯•
        if not self.cameras:
            self.cameras.append({
                'id': -1,
                'name': "è™šæ‹Ÿæ‘„åƒå¤´",
                'resolution': "640x480",
                'fps': 30,
                'available': False,
                'cap': None
            })

    def get_camera_count(self):
        """è¿”å›å¯ç”¨æ‘„åƒå¤´æ•°é‡

        Returns:
            int: å¯ç”¨æ‘„åƒå¤´æ•°é‡
        """
        return len(self.get_available_cameras())

    def get_available_cameras(self):
        """è·å–å¯ç”¨æ‘„åƒå¤´åˆ—è¡¨

        Returns:
            list: å¯ç”¨æ‘„åƒå¤´ä¿¡æ¯å­—å…¸åˆ—è¡¨
        """
        return [cam for cam in self.cameras if cam['available']]

    def get_camera_info(self, camera_id):
        """è·å–æŒ‡å®šæ‘„åƒå¤´çš„è¯¦ç»†ä¿¡æ¯

        Args:
            camera_id (int): æ‘„åƒå¤´ID

        Returns:
            dict: æ‘„åƒå¤´ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹é”®ï¼š
                - id: æ‘„åƒå¤´ç´¢å¼•
                - name: æ‘„åƒå¤´åç§°
                - resolution: åˆ†è¾¨ç‡å­—ç¬¦ä¸²(å¦‚"640x480")
                - fps: å¸§ç‡
                - available: æ˜¯å¦å¯ç”¨
        """
        for cam in self.cameras:
            if cam['id'] == camera_id:
                return cam
        return None

    def get_camera_names(self):
        """è·å–æ‰€æœ‰æ‘„åƒå¤´åç§°åˆ—è¡¨

        Returns:
            list: æ‘„åƒå¤´åç§°å­—ç¬¦ä¸²åˆ—è¡¨
        """
        return [cam['name'] for cam in self.cameras]

    def release_all(self):
        """é‡Šæ”¾æ‰€æœ‰æ‘„åƒå¤´èµ„æº"""
        for cam in self.cameras:
            if cam['cap'] is not None:
                cam['cap'].release()
                cam['cap'] = None


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ - å¤„ç†æ¨¡å‹æ‰«æå’ŒåŠ è½½"""

    def __init__(self):
        self.models_paths = [
            Path("pt_models"),
            Path("../models"),
            Path("weights"),
        ]
        self.current_model = None
        self.class_names = []

    def scan_models(self, custom_path=None):
        """æ‰«ææ¨¡å‹æ–‡ä»¶"""
        models = []
        search_paths = self.models_paths.copy()

        if custom_path and Path(custom_path).exists():
            search_paths.insert(0, Path(custom_path))

        for model_dir in search_paths:
            if model_dir.exists():
                try:
                    pt_files = sorted(model_dir.glob("*.pt"))
                    for pt_file in pt_files:
                        models.append({
                            'name': pt_file.name,
                            'path': str(pt_file),
                            'size': self._get_file_size(pt_file),
                            'modified': self._get_modification_time(pt_file)
                        })
                except Exception as e:
                    print(f"æ‰«æç›®å½• {model_dir} æ—¶å‡ºé”™: {e}")

        return models

    def load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        try:
            self.current_model = YOLO(model_path)
            self.class_names = list(self.current_model.names.values())
            return True
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def get_class_names(self):
        """è·å–ç±»åˆ«åç§°"""
        return self.class_names

    def _get_file_size(self, file_path):
        """è·å–æ–‡ä»¶å¤§å°"""
        try:
            size = file_path.stat().st_size
            for unit in ['B', 'KB', 'MB', 'GB']:
                if size < 1024.0:
                    return f"{size:.1f} {unit}"
                size /= 1024.0
            return f"{size:.1f} TB"
        except:
            return "Unknown"

    def _get_modification_time(self, file_path):
        """è·å–ä¿®æ”¹æ—¶é—´"""
        try:
            timestamp = file_path.stat().st_mtime
            return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M")
        except:
            return "Unknown"

class DetectionThread(QThread):
    """å¢å¼ºçš„æ£€æµ‹çº¿ç¨‹"""
    result_ready = Signal(object, object, float, object, list)  # åŸå›¾, ç»“æœå›¾, è€—æ—¶, æ£€æµ‹ç»“æœ, ç±»åˆ«åç§°
    progress_updated = Signal(int)
    status_changed = Signal(str)
    error_occurred = Signal(str)
    fps_updated = Signal(float)
    finished = Signal()

    def __init__(self, model, source_type, source_path=None, camera_id=0, confidence_threshold=0.25):
        super().__init__()
        self.model = model
        self.source_type = source_type
        self.source_path = source_path
        self.camera_id = camera_id
        self.confidence_threshold = confidence_threshold
        self.is_running = False
        self.is_paused = False
        self.frame_count = 0
        self.fps_counter = 0
        self.last_fps_time = time.time()

    def run(self):
        self.is_running = True
        try:
            if self.source_type == 'image':
                self._process_image()
            elif self.source_type == 'video':
                self._process_video()
            elif self.source_type == 'camera':
                self._process_camera()
        except Exception as e:
            self.error_occurred.emit(f"æ£€æµ‹è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}")
        finally:
            self.is_running = False
            self.finished.emit()

    def _process_image(self):
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        if not self.source_path or not Path(self.source_path).exists():
            self.error_occurred.emit("å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨")
            return

        self.status_changed.emit("æ­£åœ¨å¤„ç†å›¾ç‰‡...")

        start_time = time.time()
        results = self.model(self.source_path, conf=self.confidence_threshold, verbose=False)
        end_time = time.time()

        original_img = cv2.imread(self.source_path)
        if original_img is None:
            self.error_occurred.emit("æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶")
            return

        original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
        result_img = results[0].plot()
        result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
        class_names = list(self.model.names.values())

        self.result_ready.emit(original_img, result_img, end_time - start_time, results, class_names)
        self.progress_updated.emit(100)

    def _process_video(self):
        """å¤„ç†è§†é¢‘æ–‡ä»¶"""
        if not self.source_path or not Path(self.source_path).exists():
            self.error_occurred.emit("è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            return

        cap = cv2.VideoCapture(self.source_path)
        if not cap.isOpened():
            self.error_occurred.emit("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
            return

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_count = 0
        class_names = list(self.model.names.values())

        self.status_changed.emit(f"å¼€å§‹å¤„ç†è§†é¢‘ (å…±{total_frames}å¸§)...")

        while cap.isOpened() and self.is_running:
            if self.is_paused:
                time.sleep(0.1)
                continue

            ret, frame = cap.read()
            if not ret:
                break

            start_time = time.time()
            results = self.model(frame, conf=self.confidence_threshold, verbose=False)
            end_time = time.time()

            original_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result_img = results[0].plot()
            result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)

            self.result_ready.emit(original_img, result_img, end_time - start_time, results, class_names)

            frame_count += 1
            if total_frames > 0:
                progress = int((frame_count / total_frames) * 100)
                self.progress_updated.emit(progress)

            # æ›´æ–°FPS
            self._update_fps()

            # çŠ¶æ€æ›´æ–°ï¼ˆæ¯30å¸§æ›´æ–°ä¸€æ¬¡ï¼‰
            if frame_count % 30 == 0:
                current_fps = self._get_current_fps()
                self.status_changed.emit(f"å¤„ç†ä¸­... {frame_count}/{total_frames} å¸§ (FPS: {current_fps:.1f})")

            time.sleep(0.033)  # çº¦30fps

        cap.release()

    def _process_camera(self):
        """å¤„ç†æ‘„åƒå¤´"""
        cap = cv2.VideoCapture(self.camera_id)
        if not cap.isOpened():
            self.error_occurred.emit(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}")
            return

        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)

        class_names = list(self.model.names.values())
        self.status_changed.emit(f"æ‘„åƒå¤´ {self.camera_id} å·²å¯åŠ¨...")

        while cap.isOpened() and self.is_running:
            if self.is_paused:
                time.sleep(0.1)
                continue

            ret, frame = cap.read()
            if not ret:
                break

            start_time = time.time()
            results = self.model(frame, conf=self.confidence_threshold, verbose=False)
            end_time = time.time()

            original_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result_img = results[0].plot()
            result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)

            self.result_ready.emit(original_img, result_img, end_time - start_time, results, class_names)

            # æ›´æ–°FPS
            self._update_fps()

            # çŠ¶æ€æ›´æ–°ï¼ˆæ¯60å¸§æ›´æ–°ä¸€æ¬¡ï¼‰
            if self.frame_count % 60 == 0:
                current_fps = self._get_current_fps()
                self.status_changed.emit(f"æ‘„åƒå¤´è¿è¡Œä¸­ (FPS: {current_fps:.1f})")

            time.sleep(0.033)  # çº¦30fps

        cap.release()

    def _update_fps(self):
        """æ›´æ–°FPSè®¡ç®—"""
        self.frame_count += 1
        self.fps_counter += 1

        current_time = time.time()
        if current_time - self.last_fps_time >= 1.0:
            fps = self.fps_counter / (current_time - self.last_fps_time)
            self.fps_updated.emit(fps)
            self.fps_counter = 0
            self.last_fps_time = current_time

    def _get_current_fps(self):
        """è·å–å½“å‰FPS"""
        current_time = time.time()
        if current_time - self.last_fps_time > 0:
            return self.fps_counter / (current_time - self.last_fps_time)
        return 0

    def pause(self):
        self.is_paused = True
        self.status_changed.emit(f"æš‚åœä¸­...")

    def resume(self):
        self.is_paused = False
        self.status_changed.emit(f"æ¢å¤æ£€æµ‹")


    def stop(self):
        self.is_running = False
        self.status_changed.emit(f"æ£€æµ‹ç»“æŸ!")

class BatchDetectionThread(QThread):
    """æ‰¹é‡æ£€æµ‹çº¿ç¨‹"""
    result_ready = Signal(str, object, object, float, object, list)  # æ–‡ä»¶è·¯å¾„, åŸå›¾, ç»“æœå›¾, è€—æ—¶, æ£€æµ‹ç»“æœ, ç±»åˆ«åç§°
    progress_updated = Signal(int)
    current_file_changed = Signal(str)
    status_changed = Signal(str)
    error_occurred = Signal(str)
    finished = Signal()

    def __init__(self, model, folder_path, confidence_threshold=0.25, supported_formats=None):
        super().__init__()
        self.model = model
        self.folder_path = folder_path
        self.confidence_threshold = confidence_threshold
        self.supported_formats = supported_formats or ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp', '.tif']
        self.is_running = False
        self.processed_count = 0
        self.error_count = 0

    def run(self):
        self.is_running = True

        try:
            # æ”¶é›†æ‰€æœ‰æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶
            image_files = []
            for fmt in self.supported_formats:
                image_files.extend(Path(self.folder_path).rglob(f'*{fmt}'))
                # image_files.extend(Path(self.folder_path).rglob(f'*{fmt.upper()}'))

            total_files = len(image_files)
            if total_files == 0:
                self.status_changed.emit("æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ ¼å¼")
                self.finished.emit()
                return

            self.status_changed.emit(f"å¼€å§‹æ‰¹é‡å¤„ç† {total_files} ä¸ªæ–‡ä»¶...")

            # è·å–ç±»åˆ«åç§°
            class_names = list(self.model.names.values())

            for i, img_path in enumerate(image_files):
                if not self.is_running:
                    break

                self.current_file_changed.emit(str(img_path))

                try:
                    # å¤„ç†å•ä¸ªå›¾ç‰‡
                    start_time = time.time()
                    results = self.model(str(img_path), conf=self.confidence_threshold, verbose=False)
                    end_time = time.time()

                    # è·å–åŸå›¾
                    original_img = cv2.imread(str(img_path))
                    if original_img is not None:
                        original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)

                        # è·å–ç»“æœå›¾
                        result_img = results[0].plot()
                        result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)

                        self.result_ready.emit(str(img_path), original_img, result_img,
                                               end_time - start_time, results, class_names)
                        self.processed_count += 1

                except Exception as e:
                    self.error_occurred.emit(f"å¤„ç†æ–‡ä»¶ {img_path.name} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                    self.error_count += 1

                # æ›´æ–°è¿›åº¦
                progress = int(((i + 1) / total_files) * 100)
                self.progress_updated.emit(progress)

                # çŠ¶æ€æ›´æ–°
                if (i + 1) % 10 == 0 or i == total_files - 1:
                    self.status_changed.emit(
                        f"å¤„ç†è¿›åº¦: {i + 1}/{total_files} (æˆåŠŸ: {self.processed_count}, é”™è¯¯: {self.error_count})")

        except Exception as e:
            self.error_occurred.emit(f"æ‰¹é‡å¤„ç†å‘ç”Ÿé”™è¯¯: {str(e)}")
        finally:
            self.is_running = False
            # self.finished.emit()

    def stop(self):
        """åœæ­¢æ‰¹é‡æ£€æµ‹"""
        self.is_running = False


class MultiCameraMonitorThread(QThread):
    camera_result_ready = Signal(int, object, object, float, object, list)
    camera_error = Signal(int, str)
    camera_status = Signal(int, str)
    finished = Signal()

    def __init__(self, model, camera_ids, conf=0.25, fps=10):
        super().__init__()
        self.model = model
        self.cam_ids = camera_ids
        self.conf = conf
        self.period = 1.0 / fps  # å¸§é—´éš”
        self.caps = {}  # {id: cv2.VideoCapture}
        self.active = {}  # {id: bool} æ˜¯å¦åœ¨çº¿
        self.last_t = {}  # {id: float}

        # çº¿ç¨‹åŒæ­¥
        self._run_flag = True
        self._pause_cond = QWaitCondition()
        self._pause_mutex = QMutex()
        self._paused_flag = False

    # ----------------- ç”Ÿå‘½å‘¨æœŸ -----------------
    def run(self):
        self._open_all()
        if not self.caps:
            self.finished.emit()
            return

        cls_names = list(self.model.names.values())

        while self._run_flag:
            self._pause_mutex.lock()
            if self._paused_flag:
                self._pause_cond.wait(self._pause_mutex)
            self._pause_mutex.unlock()

            for cid in list(self.caps.keys()):
                if not self._run_flag:
                    break
                if not self._grab_and_infer(cid, cls_names):
                    self._reconnect_later(cid)  # æ–­çº¿åå¼‚æ­¥é‡è¿
            self.msleep(10)

        self._close_all()
        self.finished.emit()

    def stop(self):
        self._run_flag = False
        self.resume()  # ç¡®ä¿ç­‰å¾…çº¿ç¨‹è¢«å”¤é†’
        self.wait()

    def pause(self):
        self._pause_mutex.lock()
        self._paused_flag = True
        self._pause_mutex.unlock()

    def resume(self):
        self._pause_mutex.lock()
        self._paused_flag = False
        self._pause_mutex.unlock()
        self._pause_cond.wakeAll()

    # ----------------- ç§æœ‰å·¥å…· -----------------
    def _open_all(self):
        for cid in self.cam_ids:
            cap = cv2.VideoCapture(cid, cv2.CAP_DSHOW)
            if cap.isOpened():
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                cap.set(cv2.CAP_PROP_FPS, 30)
                self.caps[cid] = cap
                self.active[cid] = True
                self.last_t[cid] = 0.0
                self.camera_status.emit(cid, "å·²è¿æ¥")
            else:
                self.camera_error.emit(cid, "æ— æ³•æ‰“å¼€")
                cap.release()

    def _close_all(self):
        for cap in self.caps.values():
            cap.release()
        self.caps.clear()

    def _grab_and_infer(self, cid, cls_names):
        cap = self.caps.get(cid)
        if not cap or not cap.isOpened():
            return False

        # è¯»å¸§éé˜»å¡ï¼šå…ˆ grab å† retrieve
        if not cap.grab():
            return False

        now = time.time()
        if now - self.last_t[cid] < self.period:
            return True  # æœªè¶…æ—¶ï¼Œä½†å¸§å·² grabï¼Œé¿å…å †ç§¯
        self.last_t[cid] = now

        ret, frame = cap.retrieve()
        if not ret:
            return False

        try:
            t0 = time.time()
            results = self.model(frame, conf=self.conf, verbose=False)
            infer_ms = (time.time() - t0) * 1000
            out_img = results[0].plot()
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            rgb_out = cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB)
            self.camera_result_ready.emit(cid, rgb_frame, rgb_out,
                                          infer_ms / 1000.0, results, cls_names)
            return True
        except Exception as e:
            self.camera_error.emit(cid, f"æ¨ç†å¼‚å¸¸: {e}")
            return False

    def _reconnect_later(self, cid):
        # ç®€å•ç­–ç•¥ï¼š5 ç§’åé‡è¯•
        if self.active.get(cid) is False:
            return
        self.active[cid] = False
        self.camera_status.emit(cid, "é‡è¿ä¸­â€¦")
        threading.Timer(5.0, lambda: self._try_reopen(cid)).start()

    def _try_reopen(self, cid):
        if cid in self.caps:
            self.caps[cid].release()
        cap = cv2.VideoCapture(cid)
        if cap.isOpened():
            self.caps[cid] = cap
            self.active[cid] = True
            self.camera_status.emit(cid, "å·²é‡è¿")
        else:
            cap.release()
            self._reconnect_later(cid)


class ModelSelectionDialog(QDialog):
    """æ¨¡å‹é€‰æ‹©å¯¹è¯æ¡†"""

    def __init__(self, model_manager, parent=None):
        super().__init__(parent)
        self.model_manager = model_manager
        self.selected_model = None
        self.init_ui()

    def init_ui(self):
        self.setWindowTitle("ğŸ”§ é«˜çº§æ¨¡å‹é€‰æ‹©")
        self.setModal(True)
        self.resize(700, 450)

        layout = QVBoxLayout(self)

        # è‡ªå®šä¹‰è·¯å¾„
        path_group = QGroupBox("ğŸ“ è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„")
        path_layout = QHBoxLayout(path_group)

        self.path_edit = QLineEdit()
        self.path_edit.setPlaceholderText("è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹ç›®å½•è·¯å¾„...")
        path_layout.addWidget(self.path_edit)

        browse_btn = QPushButton("ğŸ“‚ æµè§ˆ")
        browse_btn.clicked.connect(self.browse_path)
        path_layout.addWidget(browse_btn)

        refresh_btn = QPushButton("ğŸ”„ åˆ·æ–°")
        refresh_btn.clicked.connect(self.refresh_models)
        path_layout.addWidget(refresh_btn)

        layout.addWidget(path_group)

        # æ¨¡å‹åˆ—è¡¨
        models_group = QGroupBox("ğŸ“‹ å¯ç”¨æ¨¡å‹")
        models_layout = QVBoxLayout(models_group)

        self.model_table = QTableWidget()
        self.model_table.setColumnCount(4)
        self.model_table.setHorizontalHeaderLabels(["æ¨¡å‹åç§°", "å¤§å°", "ä¿®æ”¹æ—¶é—´", "è·¯å¾„"])
        self.model_table.horizontalHeader().setSectionResizeMode(QHeaderView.Stretch)
        self.model_table.setSelectionBehavior(QTableWidget.SelectRows)
        self.model_table.setAlternatingRowColors(True)
        self.model_table.doubleClicked.connect(self.accept)

        models_layout.addWidget(self.model_table)
        layout.addWidget(models_group)

        # æŒ‰é’®
        button_box = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        button_box.accepted.connect(self.accept)
        button_box.rejected.connect(self.reject)
        layout.addWidget(button_box)

        # è®¾ç½®æ ·å¼
        self.setStyleSheet("""
            QDialog {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                    stop:0 #f8f9fa, stop:1 #e9ecef);
            }
        """)

        self.refresh_models()

    def browse_path(self):
        """æµè§ˆè‡ªå®šä¹‰è·¯å¾„"""
        path = QFileDialog.getExistingDirectory(self, "é€‰æ‹©æ¨¡å‹ç›®å½•")
        if path:
            self.path_edit.setText(path)
            self.refresh_models()

    def refresh_models(self):
        """åˆ·æ–°æ¨¡å‹åˆ—è¡¨"""
        custom_path = self.path_edit.text() if self.path_edit.text() else None
        models = self.model_manager.scan_models(custom_path)

        self.model_table.setRowCount(len(models))

        for i, model in enumerate(models):
            self.model_table.setItem(i, 0, QTableWidgetItem(model['name']))
            self.model_table.setItem(i, 1, QTableWidgetItem(model['size']))
            self.model_table.setItem(i, 2, QTableWidgetItem(model['modified']))
            self.model_table.setItem(i, 3, QTableWidgetItem(model['path']))

    def accept(self):
        """ç¡®è®¤é€‰æ‹©"""
        current_row = self.model_table.currentRow()
        if current_row >= 0:
            self.selected_model = self.model_table.item(current_row, 3).text()
        super().accept()


class DetectionResultWidget(QWidget):
    """æ£€æµ‹ç»“æœæ˜¾ç¤ºç»„ä»¶"""

    def __init__(self):
        super().__init__()
        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)

        # æ ‡é¢˜
        title = QLabel("ğŸ¯ æ£€æµ‹ç»“æœè¯¦æƒ…è¡¨")
        title.setStyleSheet("font-size: 16px; font-weight: bold; color: #2c3e50; margin-bottom: 10px;")
        # title.setAlignment(Qt.AlignCenter)
        layout.addWidget(title)

        # ç»“æœè¡¨æ ¼
        self.result_table = QTableWidget()
        self.result_table.setColumnCount(5)
        self.result_table.setHorizontalHeaderLabels(["åºå·", "ç±»åˆ«", "ç½®ä¿¡åº¦", "åæ ‡ (x,y)", "å°ºå¯¸ (wÃ—h)"])
        self.result_table.horizontalHeader().setSectionResizeMode(QHeaderView.Stretch)
        self.result_table.horizontalHeader().setStyleSheet("""
            QHeaderView::section {
                font-size: 10pt;
                font-weight: bold;
                height: 12px;     /* åœ¨ QSS é‡Œ height å¯¹è¡¨å¤´ section ç”Ÿæ•ˆ */
            }
        """)
        self.result_table.setMaximumHeight(200)
        self.result_table.setAlternatingRowColors(True)

        layout.addWidget(self.result_table)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats_label = QLabel("ç­‰å¾…æ£€æµ‹ç»“æœ...")
        self.stats_label.setStyleSheet("""
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                stop:0 rgba(236, 240, 241, 0.9), stop:1 rgba(189, 195, 199, 0.9));
            padding: 12px;
            border-radius: 8px;
            font-size: 12px;
            color: #2c3e50;
            font-weight: bold;
        """)
        layout.addWidget(self.stats_label)

    def update_results(self, results, class_names, inference_time):
        """æ›´æ–°æ£€æµ‹ç»“æœ"""
        if not results or not results[0].boxes or len(results[0].boxes) == 0:
            self.result_table.setRowCount(0)
            self.stats_label.setText("âŒ æœªæ£€æµ‹åˆ°ç›®æ ‡")
            return

        boxes = results[0].boxes
        confidences = boxes.conf.cpu().numpy()
        classes = boxes.cls.cpu().numpy().astype(int)
        xyxy = boxes.xyxy.cpu().numpy()

        # æ›´æ–°è¡¨æ ¼
        self.result_table.setRowCount(len(confidences))

        class_counts = {}
        for i, (conf, cls, box) in enumerate(zip(confidences, classes, xyxy)):
            class_name = class_names[cls] if cls < len(class_names) else f"ç±»åˆ«{cls}"

            # ç»Ÿè®¡ç±»åˆ«æ•°é‡
            class_counts[class_name] = class_counts.get(class_name, 0) + 1

            self.result_table.setItem(i, 0, QTableWidgetItem(str(i + 1)))
            self.result_table.setItem(i, 1, QTableWidgetItem(class_name))

            # ç½®ä¿¡åº¦å¸¦é¢œè‰²
            conf_item = QTableWidgetItem(f"{conf:.3f}")
            if conf > 0.8:
                conf_item.setBackground(QColor(46, 204, 113, 100))  # ç»¿è‰²
            elif conf > 0.5:
                conf_item.setBackground(QColor(241, 196, 15, 100))  # é»„è‰²
            else:
                conf_item.setBackground(QColor(231, 76, 60, 100))  # çº¢è‰²
            self.result_table.setItem(i, 2, conf_item)

            self.result_table.setItem(i, 3, QTableWidgetItem(f"({box[0]:.0f},{box[1]:.0f})"))
            self.result_table.setItem(i, 4, QTableWidgetItem(f"{box[2] - box[0]:.0f}Ã—{box[3] - box[1]:.0f}"))

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        total_objects = len(confidences)
        avg_confidence = np.mean(confidences)

        stats_text = f"âœ… æ£€æµ‹åˆ° {total_objects} ä¸ªç›®æ ‡ | "
        stats_text += f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f} | "
        stats_text += f"â±ï¸ è€—æ—¶: {inference_time:.3f}ç§’\n"
        stats_text += "ğŸ“Š ç±»åˆ«ç»Ÿè®¡: " + " | ".join([f"{name}: {count}" for name, count in class_counts.items()])

        self.stats_label.setText(stats_text)


class MonitoringWidget(QWidget):
    """ç›‘æ§é¡µé¢ç»„ä»¶"""

    def __init__(self, model_manager, camera_manager):
        super().__init__()
        self.model_manager = model_manager
        self.camera_manager = camera_manager
        self.monitoring_thread = None
        self.camera_labels = {}
        self.current_model = None
        self.start_monitor_btn = QPushButton("ğŸš€ å¼€å§‹ç›‘æ§")

        # è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§ç›¸å…³å±æ€§
        self.is_auto_saving = False
        self.camera_recorders = {}  # {camera_id: VideoRecorder}
        self.monitor_history_dir = Path("monitor_history")
        self.monitor_history_dir.mkdir(exist_ok=True)
        self.current_memory_usage = 0  # MB
        self.max_memory_limit = 500  # MB

        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)

        # æ§åˆ¶é¢æ¿
        control_group = QGroupBox("ğŸ–¥ï¸ ç›‘æ§æ§åˆ¶")
        control_group.setMaximumHeight(120)  # å¢åŠ é«˜åº¦ä»¥å®¹çº³æ–°æ§ä»¶
        control_layout = QVBoxLayout(control_group)

        # ç¬¬ä¸€è¡Œï¼šæ¨¡å‹å’Œæ‘„åƒå¤´é€‰æ‹©
        first_row_layout = QHBoxLayout()

        # æ¨¡å‹é€‰æ‹©
        model_layout = QHBoxLayout()
        model_layout.addWidget(QLabel("æ¨¡å‹:"))
        self.model_combo = QComboBox()
        self.model_combo.currentTextChanged.connect(self.on_model_changed)
        self.init_model_combo()
        model_layout.addWidget(self.model_combo)
        select_model_btn = QPushButton("ğŸ”§ é€‰æ‹©æ¨¡å‹")
        select_model_btn.clicked.connect(self.select_model)
        model_layout.addWidget(select_model_btn)
        first_row_layout.addLayout(model_layout)

        # æ‘„åƒå¤´é€‰æ‹©
        camera_layout = QHBoxLayout()
        camera_layout.addWidget(QLabel("æ‘„åƒå¤´:"))
        self.camera_list = QListWidget()
        self.camera_list.setMaximumWidth(300)
        self.camera_list.setSelectionMode(QListWidget.MultiSelection)
        self.refresh_cameras()
        camera_layout.addWidget(self.camera_list)
        refresh_camera_btn = QPushButton("ğŸ”„ åˆ·æ–°")
        refresh_camera_btn.clicked.connect(self.refresh_cameras)
        camera_layout.addWidget(refresh_camera_btn)
        first_row_layout.addLayout(camera_layout)

        control_layout.addLayout(first_row_layout)

        # ç¬¬äºŒè¡Œï¼šç›‘æ§æ§åˆ¶å’Œè‡ªåŠ¨ä¿å­˜è®¾ç½®
        second_row_layout = QHBoxLayout()

        # ç›‘æ§æ§åˆ¶æŒ‰é’®
        monitor_btn_layout = QHBoxLayout()
        self.start_monitor_btn.clicked.connect(self.start_monitoring)
        self.start_monitor_btn.setEnabled(True)
        monitor_btn_layout.addWidget(self.start_monitor_btn)

        self.stop_monitor_btn = QPushButton("â¸ï¸ æš‚åœ")
        self.stop_monitor_btn.clicked.connect(self.stop_monitoring)
        monitor_btn_layout.addWidget(self.stop_monitor_btn)

        self.clear_monitor_btn = QPushButton("ğŸ—‘ï¸ æ¸…é™¤ç›‘æ§")
        self.clear_monitor_btn.clicked.connect(self.clear_monitoring)
        self.clear_monitor_btn.setEnabled(False)
        self.stop_monitor_btn.setEnabled(False)
        monitor_btn_layout.addWidget(self.clear_monitor_btn)

        second_row_layout.addLayout(monitor_btn_layout)

        # è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§æ§åˆ¶
        snapshot_control_layout = QHBoxLayout()

        self.auto_save_btn = QPushButton("ğŸ¬ è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§")
        self.auto_save_btn.clicked.connect(self.toggle_auto_save)
        self.auto_save_btn.setEnabled(False)
        snapshot_control_layout.addWidget(self.auto_save_btn)

        # å½•åˆ¶è®¾ç½®
        snapshot_control_layout.addWidget(QLabel("å¸§ç‡:"))
        self.recording_fps_spinbox = QSpinBox()
        self.recording_fps_spinbox.setRange(5, 60)
        self.recording_fps_spinbox.setValue(20)
        self.recording_fps_spinbox.setSuffix(" fps")
        snapshot_control_layout.addWidget(self.recording_fps_spinbox)

        snapshot_control_layout.addWidget(QLabel("å†…å­˜é™åˆ¶:"))
        self.memory_limit_spinbox = QSpinBox()
        self.memory_limit_spinbox.setRange(100, 2000)
        self.memory_limit_spinbox.setValue(500)
        self.memory_limit_spinbox.setSuffix(" MB")
        snapshot_control_layout.addWidget(self.memory_limit_spinbox)

        second_row_layout.addLayout(snapshot_control_layout)

        control_layout.addLayout(second_row_layout)

        layout.addWidget(control_group)

        # ç›‘æ§æ˜¾ç¤ºåŒºåŸŸ
        self.monitor_scroll = QScrollArea()
        self.monitor_scroll.setStyleSheet("""
            QScrollArea {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 rgba(236, 240, 241, 0.9),
                    stop:1 rgba(189, 195, 199, 0.9));
                border-radius: 8px;
            }
            QScrollArea > QWidget > QWidget {   /* viewport */
                background: transparent;
            }
            QScrollArea::corner {               /* å³ä¸‹è§’ç©ºç™½ä¸‰è§’ */
                background: transparent;
            }
        """)
        self.monitor_widget = QWidget()
        self.monitor_layout = QGridLayout(self.monitor_widget)
        self.monitor_scroll.setWidget(self.monitor_widget)
        self.monitor_scroll.setWidgetResizable(True)

        layout.addWidget(self.monitor_scroll)

    def init_model_combo(self):
        """åˆå§‹åŒ–æ¨¡å‹ä¸‹æ‹‰æ¡†"""
        self.model_combo.clear()
        models = self.model_manager.scan_models()

        if not models:
            self.model_combo.addItem("æ— å¯ç”¨æ¨¡å‹")
            self.model_combo.setEnabled(False)
        else:
            self.model_combo.addItems([model['name'] for model in models])
            self.model_combo.setEnabled(True)
            self.try_load_default_model()

    def try_load_default_model(self):
        """å°è¯•åŠ è½½é»˜è®¤æ¨¡å‹"""
        if self.model_combo.count() > 0 and self.model_combo.itemText(0) != "æ— å¯ç”¨æ¨¡å‹":
            first_model = self.model_combo.itemText(0)
            self.load_model_by_name(first_model)

    def load_model_by_name(self, model_name):
        """æ ¹æ®åç§°åŠ è½½æ¨¡å‹"""
        models = self.model_manager.scan_models()
        for model in models:
            if model['name'] == model_name:
                self.load_model(model['path'])
                break

    def on_model_changed(self, model_text):
        """æ¨¡å‹é€‰æ‹©æ”¹å˜"""
        if model_text != "æ— å¯ç”¨æ¨¡å‹":
            self.load_model_by_name(model_text)

    def load_model(self, model_path):

        """åŠ è½½æ¨¡å‹"""
        try:
            self.current_model = YOLO(model_path)
            self.start_monitor_btn.setEnabled(True)
            return True
        except Exception as e:
            pass

            return False

    def select_model(self):
        """é€‰æ‹©æ¨¡å‹"""
        dialog = ModelSelectionDialog(self.model_manager, self)
        if dialog.exec() == QDialog.Accepted and dialog.selected_model:
            try:
                self.current_model = YOLO(dialog.selected_model)
                model_name = Path(dialog.selected_model).name
                self.model_combo.clear()
                self.model_combo.addItem(model_name)
                self.start_monitor_btn.setEnabled(True)
                QMessageBox.information(self, "æˆåŠŸ", f"æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
            except Exception as e:
                QMessageBox.critical(self, "é”™è¯¯", f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

    def refresh_cameras(self):
        """åˆ·æ–°æ‘„åƒå¤´åˆ—è¡¨"""
        self.camera_manager.scan_cameras()
        self.camera_list.clear()

        for camera in self.camera_manager.get_available_cameras():
            item = QListWidgetItem(f"ğŸ“¹ {camera['name']} ({camera['resolution']})")
            item.setData(Qt.UserRole, camera['id'])
            self.camera_list.addItem(item)

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if not self.current_model:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹")
            return

        selected_items = self.camera_list.selectedItems()
        if not selected_items:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ‘„åƒå¤´")
            return

        camera_ids = [item.data(Qt.UserRole) for item in selected_items]

        # æ¸…ç©ºä¹‹å‰çš„æ˜¾ç¤º
        self.clear_monitor_display()
        self.clear_monitor_btn.setEnabled(True)

        # åˆ›å»ºæ˜¾ç¤ºæ ‡ç­¾
        self.create_camera_labels(camera_ids)
        # è®¾ç½®ç­‰é«˜å®½
        self.set_equal_column_stretch()
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.monitoring_thread = MultiCameraMonitorThread(self.current_model, camera_ids)
        self.monitoring_thread.camera_result_ready.connect(self.update_camera_display)
        self.monitoring_thread.camera_error.connect(self.handle_camera_error)
        self.monitoring_thread.finished.connect(self.on_monitoring_finished)

        self.monitoring_thread.start()

        self.start_monitor_btn.setEnabled(False)
        self.stop_monitor_btn.setEnabled(True)
        self.auto_save_btn.setEnabled(True)  # å¯ç”¨è‡ªåŠ¨ä¿å­˜æŒ‰é’®

    def stop_monitoring(self):
        """æš‚åœ/ç»§ç»­ç›‘æ§"""
        if self.monitoring_thread and self.monitoring_thread._run_flag:
            if self.monitoring_thread._paused_flag:  # ç›‘æµ‹æ˜¯å¦å·²æš‚åœ
                self.monitoring_thread.resume()  # æ¢å¤
                self.stop_monitor_btn.setText("â¸ï¸ æš‚åœ")  # æŒ‰é’®æ–‡å­—ï¼šæš‚åœ
            else:
                self.monitoring_thread.pause()  # æš‚åœ
                self.stop_monitor_btn.setText("â–¶ï¸ ç»§ç»­")  # æŒ‰é’®æ–‡å­—ï¼šç»§ç»­

    def clear_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring_thread.stop()
        self.clear_monitor_display()

        # åœæ­¢è‡ªåŠ¨ä¿å­˜
        if self.is_auto_saving:
            self.stop_auto_save()

        # é‡ç½®æŒ‰é’®çŠ¶æ€
        self.start_monitor_btn.setEnabled(True)
        self.stop_monitor_btn.setEnabled(False)
        self.clear_monitor_btn.setEnabled(False)
        self.auto_save_btn.setEnabled(False)

    def create_camera_labels(self, camera_ids):
        """åˆ›å»ºæ‘„åƒå¤´æ˜¾ç¤ºæ ‡ç­¾"""
        self.camera_labels = {}

        cols = 2  # æ¯è¡Œ2ä¸ªæ‘„åƒå¤´
        for i, camera_id in enumerate(camera_ids):
            row = i // cols
            col = i % cols

            # åˆ›å»ºæ‘„åƒå¤´ç»„
            camera_group = QGroupBox(f"ğŸ“¹ æ‘„åƒå¤´ {camera_id}")
            camera_group.setStyleSheet("""
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                    stop:0 rgba(248, 249, 250, 0.9), stop:1 rgba(233, 236, 239, 0.9));
                color: #7f8c8d;
                font-weight: bold;
                font-size: 14px;
                border-radius: 10px;

            """)
            # camera_group.setMaximumHeight(350)
            camera_layout = QVBoxLayout(camera_group)
            self.start_btn = QPushButton("â–¶ï¸")
            self.start_btn.setObjectName("startBtn")
            self.start_btn.setToolTip("å¯åŠ¨æ£€æµ‹")
            # self.start_btn.clicked.connect(self.start_detection)

            self.pause_btn = QPushButton("â¸ï¸")
            self.pause_btn.setObjectName("pauseBtn")
            self.pause_btn.setToolTip("æš‚åœæ£€æµ‹")
            # self.pause_btn.clicked.connect(self.pause_detection)

            self.stop_btn = QPushButton("â¹ï¸")
            self.stop_btn.setObjectName("stopBtn")
            self.stop_btn.setToolTip("åœæ­¢æ£€æµ‹")
            # self.stop_btn.clicked.connect(self.stop_detection)

            self.monitor_btn = QPushButton("ğŸ‘ï¸")
            self.monitor_btn.setObjectName("monitorBtn")
            self.monitor_btn.setToolTip("ç›‘æ§æ¨¡å¼")
            # self.monitor_btn.clicked.connect(self.toggle_monitor_mode)

            self.clear_btn = QPushButton("ğŸ—‘ï¸")
            self.clear_btn.setObjectName("clearBtn")
            self.clear_btn.setToolTip("æ¸…ç©ºç”»é¢")
            # self.clear_btn.clicked.connect(self.clear_frame)

            # çŠ¶æ€æ ‡ç­¾
            status_label = QLabel("çŠ¶æ€: åˆå§‹åŒ–ä¸­...")
            status_label.setStyleSheet("color: #7f8c8d; font-size: 10px;")

            control_layout = QHBoxLayout()
            control_layout.addWidget(self.start_btn)
            control_layout.addWidget(self.pause_btn)
            control_layout.addWidget(self.stop_btn)
            control_layout.addWidget(self.monitor_btn)
            control_layout.addWidget(self.clear_btn)
            control_layout.addStretch()
            control_layout.addWidget(status_label)

            # å›¾åƒæ˜¾ç¤ºæ ‡ç­¾
            image_label = QLabel("ç­‰å¾…è¿æ¥...")
            image_label.setMinimumSize(300, 240)
            # image_label.setMaximumHeight(350)
            image_label.setStyleSheet("""
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                    stop:0 rgba(248, 249, 250, 0.9), stop:1 rgba(233, 236, 239, 0.9));
                color: #7f8c8d;
                font-weight: bold;
                font-size: 14px;
                border-radius: 10px;

            """)
            image_label.setAlignment(Qt.AlignCenter)
            image_label.setScaledContents(True)

            camera_layout.addWidget(image_label, stretch=6)

            camera_layout.addLayout(control_layout)
            camera_layout.addStretch()

            self.camera_labels[camera_id] = {
                'image': image_label,
                'status': status_label,
                'group': camera_group
            }
            self.setStyleSheet("""
                QPushButton#startBtn {
                    max-width: 24px;
                    text-align: left;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 5px;
                    background-color: #f8f9fa;
                    color: #7f8c8d;
                    font-weight: bold;
                    font-size: 14px;
                }
                QPushButton#startBtn:hover {
                    background-color: #e9ecef;
                }
                QPushButton#startBtn:pressed {
                    background-color: #dcdcdc;
                }

                QPushButton#pauseBtn {
                    max-width: 24px;
                    text-align: left;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 5px;
                    background-color: #f8f9fa;
                    color: #7f8c8d;
                    font-weight: bold;
                    font-size: 14px;
                }
                QPushButton#pauseBtn:hover {
                    background-color: #e9ecef;
                }
                QPushButton#pauseBtn:pressed {
                    background-color: #dcdcdc;
                }

                QPushButton#stopBtn {
                    max-width: 24px;
                    text-align: left;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 5px;
                    background-color: #f8f9fa;
                    color: #7f8c8d;
                    font-weight: bold;
                    font-size: 14px;
                }
                QPushButton#stopBtn:hover {
                    background-color: #e9ecef;
                }
                QPushButton#stopBtn:pressed {
                    background-color: #dcdcdc;
                }

                QPushButton#monitorBtn {
                    max-width: 24px;
                    text-align: left;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 5px;
                    background-color: #f8f9fa;
                    color: #7f8c8d;
                    font-weight: bold;
                    font-size: 14px;
                }
                QPushButton#monitorBtn:hover {
                    background-color: #e9ecef;
                }
                QPushButton#monitorBtn:pressed {
                    background-color: #dcdcdc;
                }

                QPushButton#clearBtn {
                    max-width: 24px;
                    text-align: left;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 5px;
                    background-color: #f8f9fa;
                    color: #7f8c8d;
                    font-weight: bold;
                    font-size: 14px;
                }
                QPushButton#clearBtn:hover {
                    background-color: #e9ecef;
                }
                QPushButton#clearBtn:pressed {
                    background-color: #dcdcdc;
                }

                QLabel {
                    color: #7f8c8d;
                    font-size: 10px;
                }
            """)
            self.monitor_layout.addWidget(camera_group, row, col)

    def set_equal_column_stretch(self):
        for c in range(self.monitor_layout.columnCount()):
            self.monitor_layout.setColumnStretch(c, 1)
        for r in range(self.monitor_layout.rowCount()):
            self.monitor_layout.setRowStretch(r, 1)

    def clear_monitor_display(self):
        """æ¸…ç©ºç›‘æ§æ˜¾ç¤º"""
        for camera_id in list(self.camera_labels.keys()):
            self.camera_labels[camera_id]['group'].deleteLater()
        self.camera_labels.clear()

    def update_camera_display(self, camera_id, original_img, result_img, inference_time, results, class_names):
        """æ›´æ–°æ‘„åƒå¤´æ˜¾ç¤º"""
        if camera_id not in self.camera_labels:
            return

        # æ˜¾ç¤ºç»“æœå›¾
        self.display_image(result_img, self.camera_labels[camera_id]['image'])

        # æ›´æ–°çŠ¶æ€
        if results and results[0].boxes and len(results[0].boxes) > 0:
            object_count = len(results[0].boxes)
            self.camera_labels[camera_id]['status'].setText(
                f"çŠ¶æ€: æ£€æµ‹åˆ° {object_count} ä¸ªç›®æ ‡ | è€—æ—¶: {inference_time:.3f}s"
            )

            # æ·»åŠ æ£€æµ‹å¸§åˆ°è‡ªåŠ¨ä¿å­˜ç³»ç»Ÿ
            detection_info = {
                'results': results,
                'class_names': class_names,
                'inference_time': inference_time
            }
            self.add_detection_frame(camera_id, result_img, detection_info)
        else:
            self.camera_labels[camera_id]['status'].setText(
                f"çŠ¶æ€: æ— ç›®æ ‡ | è€—æ—¶: {inference_time:.3f}s"
            )

    def handle_camera_error(self, camera_id, error_msg):
        """å¤„ç†æ‘„åƒå¤´é”™è¯¯"""
        if camera_id in self.camera_labels:
            self.camera_labels[camera_id]['status'].setText(f"é”™è¯¯: {error_msg}")
            self.camera_labels[camera_id]['status'].setStyleSheet("color: red; font-size: 10px;")

    def on_monitoring_finished(self):
        """ç›‘æ§ç»“æŸ"""
        self.start_monitor_btn.setEnabled(True)
        self.stop_monitor_btn.setEnabled(False)

        for camera_id in self.camera_labels:
            self.camera_labels[camera_id]['status'].setText("çŠ¶æ€: å·²åœæ­¢")

    def display_image(self, img_array, label):
        """æ˜¾ç¤ºå›¾åƒ"""
        if img_array is None:
            return

        height, width, channel = img_array.shape
        bytes_per_line = 3 * width
        q_image = QImage(img_array.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
        label.setPixmap(scaled_pixmap)

    def toggle_auto_save(self):
        """åˆ‡æ¢è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§çŠ¶æ€"""
        if not self.is_auto_saving:
            self.start_auto_save()
        else:
            self.stop_auto_save()

    def start_auto_save(self):
        """å¼€å§‹è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§"""
        if not self.current_model:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹")
            return

        self.is_auto_saving = True
        self.max_memory_limit = self.memory_limit_spinbox.value()

        self.auto_save_btn.setText("â¹ï¸ åœæ­¢è‡ªåŠ¨ä¿å­˜")

        # ç¦ç”¨è®¾ç½®æ§ä»¶
        self.recording_fps_spinbox.setEnabled(False)
        self.memory_limit_spinbox.setEnabled(False)

        QMessageBox.information(self, "æˆåŠŸ", "è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§å·²å¯åŠ¨")

    def stop_auto_save(self):
        """åœæ­¢è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§"""
        self.is_auto_saving = False

        # åœæ­¢æ‰€æœ‰å½•åˆ¶å™¨
        for recorder in self.camera_recorders.values():
            recorder.stop_recording()
        self.camera_recorders.clear()

        self.auto_save_btn.setText("ğŸ¬ è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§")
        # å¯ç”¨è®¾ç½®æ§ä»¶
        self.recording_fps_spinbox.setEnabled(True)
        self.memory_limit_spinbox.setEnabled(True)

        QMessageBox.information(self, "æˆåŠŸ", "è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§å·²åœæ­¢")

    def add_detection_frame(self, camera_id, frame, detection_info):
        """æ·»åŠ æ£€æµ‹å¸§åˆ°è‡ªåŠ¨ä¿å­˜ç³»ç»Ÿ"""
        if not self.is_auto_saving:
            return

        # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹ç»“æœ
        if not detection_info or not detection_info.get('results'):
            return

        results = detection_info['results']
        if not hasattr(results[0], 'boxes') or not results[0].boxes or len(results[0].boxes) == 0:
            return

        # è·å–æ‘„åƒå¤´åç§°
        camera_name = f"æ‘„åƒå¤´{camera_id}"
        if camera_id in self.camera_labels:
            camera_name = f"æ‘„åƒå¤´{camera_id}"

        # åˆ›å»ºæˆ–è·å–å½•åˆ¶å™¨
        if camera_id not in self.camera_recorders:
            self.camera_recorders[camera_id] = CameraVideoRecorder(
                camera_id, camera_name, self.monitor_history_dir,
                self.recording_fps_spinbox.value()
            )
            # å¼€å§‹å½•åˆ¶
            self.camera_recorders[camera_id].start_recording()

        # æ·»åŠ å¸§åˆ°å½•åˆ¶å™¨
        self.camera_recorders[camera_id].add_frame(frame, detection_info)

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
        self.check_memory_usage()

    def check_memory_usage(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œè¶…è¿‡é™åˆ¶æ—¶æ¸…ç†æœ€æ—§çš„è®°å½•"""
        # è®¡ç®—å½“å‰å†…å­˜ä½¿ç”¨
        total_size = 0
        for json_file in self.monitor_history_dir.glob("*.json"):
            mp4_file = json_file.with_suffix('.mp4')
            if mp4_file.exists():
                total_size += mp4_file.stat().st_size

        current_usage_mb = total_size / (1024 * 1024)

        if current_usage_mb > self.max_memory_limit:
            # åˆ é™¤æœ€æ—§çš„è®°å½•
            self.cleanup_oldest_records()

    def cleanup_oldest_records(self):
        """æ¸…ç†æœ€æ—§çš„è®°å½•"""
        json_files = list(self.monitor_history_dir.glob("*.json"))
        if not json_files:
            return

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„
        json_files.sort(key=lambda x: x.stat().st_mtime)

        for json_file in json_files[:len(json_files) // 4]:  # åˆ é™¤25%çš„æœ€æ—§è®°å½•
            mp4_file = json_file.with_suffix('.mp4')
            try:
                if json_file.exists():
                    json_file.unlink()
                if mp4_file.exists():
                    mp4_file.unlink()
            except Exception as e:
                print(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {json_file}: {e}")


class CameraVideoRecorder:
    """æ‘„åƒå¤´è§†é¢‘å½•åˆ¶å™¨"""

    def __init__(self, camera_id, camera_name, output_dir, fps=20):
        self.camera_id = camera_id
        self.camera_name = camera_name
        self.output_dir = output_dir
        self.fps = fps
        self.is_recording = False
        self.video_writer = None
        self.frames = []
        self.detection_stats = {}
        self.total_detections = 0
        self.start_time = None
        self.end_time = None
        self.max_frames_per_file = fps * 30  # 30ç§’çš„è§†é¢‘

    def start_recording(self):
        """å¼€å§‹å½•åˆ¶"""
        if self.is_recording:
            return

        self.is_recording = True
        self.start_time = time.time()
        self.frames.clear()
        self.detection_stats.clear()
        self.total_detections = 0

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = int(self.start_time)
        self.filename_base = f"{self.camera_name}_{timestamp}"
        self.mp4_path = self.output_dir / f"{self.filename_base}.mp4"
        self.json_path = self.output_dir / f"{self.filename_base}.json"

        # åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨ï¼ˆç¨ååœ¨æ·»åŠ ç¬¬ä¸€å¸§æ—¶è®¾ç½®ï¼‰
        self.video_writer = None

    def add_frame(self, frame, detection_info):
        """æ·»åŠ å¸§"""
        if not self.is_recording:
            return

        # å¦‚æœæ˜¯ç¬¬ä¸€å¸§ï¼Œåˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨
        if self.video_writer is None:
            height, width = frame.shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            self.video_writer = cv2.VideoWriter(str(self.mp4_path), fourcc, self.fps, (width, height))

        # å†™å…¥å¸§ - è§£å†³è‰²å·®é—®é¢˜ï¼šå°†RGBè½¬æ¢ä¸ºBGR
        if frame.shape[2] == 3:  # ç¡®ä¿æ˜¯3é€šé“å½©è‰²å›¾åƒ
            bgr_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            self.video_writer.write(bgr_frame)
        else:
            self.video_writer.write(frame)

        self.frames.append(frame.copy())

        # æ›´æ–°æ£€æµ‹ç»Ÿè®¡
        if detection_info and detection_info.get('results'):
            results = detection_info['results']
            if hasattr(results[0], 'boxes') and results[0].boxes and len(results[0].boxes) > 0:
                self.total_detections += len(results[0].boxes)

                # ç»Ÿè®¡ç±»åˆ«
                if hasattr(results[0].boxes, 'cls'):
                    classes = results[0].boxes.cls.cpu().numpy().astype(int)
                    class_names = detection_info.get('class_names', [])

                    for cls in classes:
                        if cls < len(class_names):
                            class_name = class_names[cls]
                            self.detection_stats[class_name] = self.detection_stats.get(class_name, 0) + 1

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ–‡ä»¶
        if len(self.frames) >= self.max_frames_per_file:
            self.save_recording()
            self.start_recording()  # å¼€å§‹æ–°çš„å½•åˆ¶

    def stop_recording(self):
        """åœæ­¢å½•åˆ¶"""
        if not self.is_recording:
            return

        self.is_recording = False
        self.end_time = time.time()

        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None

        # ä¿å­˜å½•åˆ¶
        if self.frames:
            self.save_recording()

    def save_recording(self):
        """ä¿å­˜å½•åˆ¶"""
        if not self.frames or not self.start_time:
            return

        # ç¡®ä¿è§†é¢‘å†™å…¥å™¨å·²é‡Šæ”¾
        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None

        # ä¿å­˜JSONå…ƒæ•°æ®
        metadata = {
            'camera_id': self.camera_id,
            'camera_name': self.camera_name,
            'start_time': self.start_time,
            'end_time': self.end_time or time.time(),
            'fps': self.fps,
            'total_detections': self.total_detections,
            'detection_stats': self.detection_stats,
            'frame_count': len(self.frames),
            'mp4_filename': self.mp4_path.name,
            'json_filename': self.json_path.name
        }

        with open(self.json_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"ä¿å­˜ç›‘æ§å¿«ç…§: {self.camera_name} - {len(self.frames)} å¸§, {self.total_detections} æ¬¡æ£€æµ‹")
        print(f"æ–‡ä»¶è·¯å¾„: {self.mp4_path}")
        print(f"JSONè·¯å¾„: {self.json_path}")


class VideoWidget(QWidget):
    """è‡ªå®šä¹‰è§†é¢‘æ˜¾ç¤ºç»„ä»¶ï¼Œå¸¦æ§åˆ¶åŠŸèƒ½"""

    def __init__(self, camera_id=0, parent=None):
        super().__init__(parent)
        self.camera_id = camera_id
        self.current_frame = None
        self.detection_state = "NORMAL"  # {0: 'Fall Detected', 1: 'Walking', 2: 'Sitting'}
        self.confidence = 0.0
        self.is_monitoring = False

        self.setup_ui()
        self.setMinimumSize(320, 240)

    def setup_ui(self):
        layout = QVBoxLayout(self)
        layout.setContentsMargins(5, 5, 5, 5)

        # è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
        self.video_label = QLabel('è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ')
        self.video_label.setStyleSheet(StyleManager.get_video_label_style())
        self.video_label.setAlignment(Qt.AlignCenter)
        # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
        control_layout = QHBoxLayout()

        self.start_btn = QPushButton("â–¶ï¸")
        self.start_btn.setObjectName("startBtn")
        self.start_btn.setToolTip("å¯åŠ¨æ£€æµ‹")
        self.start_btn.clicked.connect(self.start_detection)

        self.pause_btn = QPushButton("â¸ï¸")
        self.pause_btn.setObjectName("pauseBtn")
        self.pause_btn.setToolTip("æš‚åœæ£€æµ‹")
        self.pause_btn.clicked.connect(self.pause_detection)

        self.stop_btn = QPushButton("â¹ï¸")
        self.stop_btn.setObjectName("stopBtn")
        self.stop_btn.setToolTip("åœæ­¢æ£€æµ‹")
        self.stop_btn.clicked.connect(self.stop_detection)

        self.monitor_btn = QPushButton("ğŸ‘ï¸")
        self.monitor_btn.setObjectName("monitorBtn")
        self.monitor_btn.setToolTip("ç›‘æ§æ¨¡å¼")
        self.monitor_btn.clicked.connect(self.toggle_monitor_mode)

        self.clear_btn = QPushButton("ğŸ—‘ï¸")
        self.clear_btn.setObjectName("clearBtn")
        self.clear_btn.setToolTip("æ¸…ç©ºç”»é¢")
        self.clear_btn.clicked.connect(self.clear_frame)

        # çŠ¶æ€æ ‡ç­¾
        self.status_label = QLabel("ğŸŸ¢ å°±ç»ª")

        control_layout.addWidget(self.start_btn)
        control_layout.addWidget(self.pause_btn)
        control_layout.addWidget(self.stop_btn)
        control_layout.addWidget(self.monitor_btn)
        control_layout.addWidget(self.clear_btn)
        control_layout.addWidget(self.status_label)

        control_layout.addStretch()

        layout.addWidget(self.video_label, stretch=6)
        layout.addLayout(control_layout)
        self.setStyleSheet(StyleManager.get_main_stylesheet())

    def update_frame(self, frame, state="NORMAL", confidence=0.0):
        """æ›´æ–°è§†é¢‘å¸§"""
        if self.is_monitoring:
            # ç›‘æ§æ¨¡å¼ä¸‹åªæ˜¾ç¤ºåŸå§‹ç”»é¢
            self.current_frame = frame
            self.display_frame(frame)
            return

        self.current_frame = frame
        self.detection_state = state
        self.confidence = confidence

        # æ ¹æ®çŠ¶æ€è®¾ç½®æ˜¾ç¤ºæ ·å¼  {0: 'Fall Detected', 1: 'Walking', 2: 'Sitting'}
        if state == "Fall Detected":
            self.status_label.setText(f"âš ï¸ è·Œå€’æ£€æµ‹ (ç½®ä¿¡åº¦: {confidence:.2f})")
            self.status_label.setStyleSheet("""
                QLabel {
                    color: #B91C1C;
                    background: rgba(220, 38, 38, 0.1);
                    border: 1px solid #DC2626;
                }
            """)
        elif state == "Walking":
            self.status_label.setText(f"ğŸš¶ è¡Œèµ°ä¸­ (ç½®ä¿¡åº¦: {confidence:.2f})")
            self.status_label.setStyleSheet("""
                QLabel {
                    color: #2563EB;
                    background: rgba(59, 130, 246, 0.1);
                    border: 1px solid #3B82F6;
                }
            """)
        else:
            self.status_label.setText(f"ğŸª‘ åç€ (ç½®ä¿¡åº¦: {confidence:.2f})")
            self.status_label.setStyleSheet("""
                QLabel {
                    color: #059669;
                    background: rgba(16, 185, 129, 0.1);
                    border: 1px solid #10B981;
                }
            """)

        self.display_frame(frame)

    def display_frame(self, frame):
        """æ˜¾ç¤ºè§†é¢‘å¸§"""
        if frame is None:
            return

        # è½¬æ¢OpenCVå›¾åƒåˆ°QImage
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = frame_rgb.shape
        bytes_per_line = ch * w
        q_img = QImage(frame_rgb.data, w, h, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_img)

        # ç¼©æ”¾å›¾åƒé€‚åº”æ ‡ç­¾å¤§å°
        scaled_pixmap = pixmap.scaled(
            self.video_label.size(),
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )
        self.video_label.setPixmap(scaled_pixmap)

    def start_detection(self, camera_id=None):
        """å¯åŠ¨æ£€æµ‹"""
        if camera_id is not None:
            self.camera_id = camera_id

        self.is_monitoring = False
        self.status_label.setText("ğŸŸ¡ æ£€æµ‹ä¸­...")

        # TODO: å®é™…å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹é€»è¾‘
        print(f"å¯åŠ¨æ‘„åƒå¤´ {self.camera_id} æ£€æµ‹")

    def pause_detection(self):
        """æš‚åœæ£€æµ‹"""
        self.status_label.setText("â¸ï¸ å·²æš‚åœ")

        # TODO: å®é™…æš‚åœæ£€æµ‹é€»è¾‘
        print(f"æš‚åœæ‘„åƒå¤´ {self.camera_id} æ£€æµ‹")

    def stop_detection(self):
        """åœæ­¢æ£€æµ‹"""
        self.status_label.setText("â¹ï¸ å·²åœæ­¢")

        # TODO: å®é™…åœæ­¢æ£€æµ‹é€»è¾‘
        print(f"åœæ­¢æ‘„åƒå¤´ {self.camera_id} æ£€æµ‹")

    def toggle_monitor_mode(self):
        """åˆ‡æ¢ç›‘æ§æ¨¡å¼"""
        self.is_monitoring = not self.is_monitoring
        if self.is_monitoring:
            self.monitor_btn.setText("ğŸ”")
            self.monitor_btn.setToolTip("é€€å‡ºç›‘æ§æ¨¡å¼")
            self.status_label.setText("ğŸ‘ï¸ ç›‘æ§æ¨¡å¼")

        else:
            self.monitor_btn.setText("ğŸ‘ï¸")
            self.monitor_btn.setToolTip("ç›‘æ§æ¨¡å¼")
            self.status_label.setText("ğŸŸ¢ å°±ç»ª")

        print(f"æ‘„åƒå¤´ {self.camera_id} ç›‘æ§æ¨¡å¼: {self.is_monitoring}")

    def clear_frame(self):
        """æ¸…ç©ºç”»é¢"""
        self.video_label.clear()
        self.video_label.setText("æ‘„åƒå¤´æœªæ¿€æ´»")
        self.status_label.setText("âšª ç©ºé—²")

        print(f"æ¸…ç©ºæ‘„åƒå¤´ {self.camera_id} ç”»é¢")

    def set_monitor_mode(self, enable):
        """è®¾ç½®ç›‘æ§æ¨¡å¼"""
        self.is_monitoring = enable
        self.toggle_monitor_mode()


import time
import cv2
import numpy as np
from PySide6.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, QGridLayout, QPushButton,
                               QLabel, QListWidget, QListWidgetItem, QGroupBox, QScrollArea,
                               QMessageBox, QComboBox, QDialog, QFileDialog, QTableWidget,
                               QTableWidgetItem, QHeaderView, QSlider, QSpinBox, QTextEdit)
from PySide6.QtCore import Qt, QTimer, QDateTime, QThread, Signal, Slot, QSize
from PySide6.QtGui import QImage, QPixmap, QFont, QColor
from pathlib import Path
import os
import json


class CameraThread(QThread):
    """æ‘„åƒå¤´çº¿ç¨‹ï¼Œè´Ÿè´£æ•è·å’Œå¤„ç†è§†é¢‘æµ"""
    frame_ready = Signal(int, np.ndarray, str, int)  # camera_id, image, status, detection_result

    def __init__(self, camera_id, model=None):
        super().__init__()
        self.camera_id = camera_id
        self.model = model
        self._run_flag = True
        self._paused_flag = False
        self.cap = None

    def run(self):
        """ä¸»çº¿ç¨‹é€»è¾‘"""
        try:
            self.cap = cv2.VideoCapture(self.camera_id)
            if not self.cap.isOpened():
                self.frame_ready.emit(self.camera_id, None, f"é”™è¯¯: æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}", -1)
                return

            self.frame_ready.emit(self.camera_id, None, "çŠ¶æ€: è¿è¡Œä¸­", -1)

            while self._run_flag:
                if not self._paused_flag:
                    ret, frame = self.cap.read()
                    if not ret:
                        self.frame_ready.emit(self.camera_id, None, f"é”™è¯¯: æ— æ³•è¯»å–æ‘„åƒå¤´ {self.camera_id}", -1)
                        break

                    # è½¬æ¢é¢œè‰²ç©ºé—´ BGR -> RGB
                    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                    # å¦‚æœæœ‰æ¨¡å‹ï¼Œè¿›è¡Œæ£€æµ‹
                    detection_result = -1  # -1è¡¨ç¤ºæ— æ£€æµ‹ç»“æœ
                    if self.model:
                        # è¿™é‡Œåº”è¯¥æ˜¯æ‚¨çš„æ¨¡å‹æ£€æµ‹é€»è¾‘
                        # å‡è®¾æ¨¡å‹è¿”å›æ£€æµ‹ç»“æœ (0: æ‘”å€’, 1: è¡Œèµ°, 2: åä¸‹)
                        # å®é™…å®ç°éœ€è¦æ ¹æ®æ‚¨çš„æ¨¡å‹è°ƒæ•´
                        detection_result = self.detect_with_model(rgb_image)

                    self.frame_ready.emit(self.camera_id, rgb_image,
                                          f"çŠ¶æ€: è¿è¡Œä¸­ - {self.get_status_text(detection_result)}",
                                          detection_result)

                # æ§åˆ¶å¸§ç‡
                time.sleep(0.03)  # ~30fps

        except Exception as e:
            self.frame_ready.emit(self.camera_id, None, f"é”™è¯¯: {str(e)}", -1)
        finally:
            if self.cap:
                self.cap.release()

    def detect_with_model(self, image):
        """ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ£€æµ‹"""
        # è¿™é‡Œåº”è¯¥æ˜¯æ‚¨çš„å®é™…æ¨¡å‹æ£€æµ‹ä»£ç 
        # è¿”å›æ£€æµ‹ç»“æœ (0: æ‘”å€’, 1: è¡Œèµ°, 2: åä¸‹)
        # ç¤ºä¾‹: éšæœºè¿”å›ä¸€ä¸ªç»“æœç”¨äºæ¼”ç¤º
        return np.random.randint(0, 3)

    def get_status_text(self, result):
        """è·å–çŠ¶æ€æ–‡æœ¬"""
        status_map = {
            -1: "æ— æ£€æµ‹",
            0: "æ£€æµ‹åˆ°æ‘”å€’",
            1: "æ£€æµ‹åˆ°è¡Œèµ°",
            2: "æ£€æµ‹åˆ°åä¸‹"
        }
        return status_map.get(result, "æœªçŸ¥çŠ¶æ€")

    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self._run_flag = False
        self.wait()

    def pause(self):
        """æš‚åœçº¿ç¨‹"""
        self._paused_flag = True

    def resume(self):
        """æ¢å¤çº¿ç¨‹"""
        self._paused_flag = False


class EnhancedMonitoringWidget(QWidget):
    """å¢å¼ºç‰ˆç›‘æ§é¡µé¢ç»„ä»¶ï¼Œæ”¯æŒå››åˆ†å±åŠ¨æ€å¸ƒå±€"""

    def __init__(self, model_manager, camera_manager):
        super().__init__()
        self.model_manager = model_manager
        self.camera_manager = camera_manager
        self.camera_threads = {}  # å­˜å‚¨æ‘„åƒå¤´çº¿ç¨‹
        self.camera_widgets = {}  # å­˜å‚¨æ¯ä¸ªæ‘„åƒå¤´çš„æ§ä»¶å’ŒçŠ¶æ€
        self.current_model = None
        self.detection_stats = {0: 0, 1: 0, 2: 0}  # æ‘”å€’æ£€æµ‹ç»Ÿè®¡
        self.init_ui()
        self.init_timer()

    def init_timer(self):
        """åˆå§‹åŒ–å®šæ—¶å™¨ç”¨äºæ›´æ–°æ—¶é—´"""
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_time)
        self.timer.start(1000)  # æ¯ç§’æ›´æ–°ä¸€æ¬¡

    def init_ui(self):
        layout = QVBoxLayout(self)

        # é¡¶éƒ¨æ§åˆ¶åŒºåŸŸ
        self.init_control_panel(layout)

        # ç›‘æ§æ˜¾ç¤ºåŒºåŸŸ
        self.init_monitor_area(layout)

    def init_control_panel(self, parent_layout):
        """åˆå§‹åŒ–æ§åˆ¶é¢æ¿"""
        control_group = QGroupBox("ğŸ–¥ï¸ ç›‘æ§æ§åˆ¶")
        control_layout = QHBoxLayout(control_group)

        # å·¦ä¾§åŒºåŸŸï¼šæ¨¡å‹å’Œæ‘„åƒå¤´é€‰æ‹©
        left_panel = QVBoxLayout()

        # æ¨¡å‹é€‰æ‹©
        model_layout = QHBoxLayout()
        model_layout.addWidget(QLabel("æ¨¡å‹:"))

        self.model_combo = QComboBox()
        self.model_combo.currentTextChanged.connect(self.on_model_changed)
        self.init_model_combo()
        model_layout.addWidget(self.model_combo)

        select_model_btn = QPushButton("ğŸ”§ é€‰æ‹©æ¨¡å‹")
        select_model_btn.clicked.connect(self.select_model)
        model_layout.addWidget(select_model_btn)
        left_panel.addLayout(model_layout)

        # æ‘„åƒå¤´é€‰æ‹©
        camera_layout = QHBoxLayout()
        camera_layout.addWidget(QLabel("æ‘„åƒå¤´:"), stretch=4)

        self.camera_list = QListWidget()
        self.camera_list.setMaximumWidth(300)
        self.camera_list.setSelectionMode(QListWidget.MultiSelection)
        self.refresh_cameras()
        camera_layout.addWidget(self.camera_list)

        refresh_camera_btn = QPushButton("ğŸ”„ åˆ·æ–°")
        refresh_camera_btn.clicked.connect(self.refresh_cameras)
        camera_layout.addWidget(refresh_camera_btn)
        left_panel.addLayout(camera_layout)

        control_layout.addLayout(left_panel)

        # ä¸­é—´åŒºåŸŸï¼šå…¨å±€æ§åˆ¶æŒ‰é’®
        center_panel = QVBoxLayout()
        btn_layout = QHBoxLayout()

        self.start_all_btn = QPushButton("ğŸš€ å…¨éƒ¨å¼€å§‹")
        self.start_all_btn.clicked.connect(self.start_all_cameras)
        btn_layout.addWidget(self.start_all_btn)

        self.pause_all_btn = QPushButton("â¸ï¸ å…¨éƒ¨æš‚åœ")
        self.pause_all_btn.clicked.connect(self.pause_all_cameras)
        self.pause_all_btn.setEnabled(False)
        btn_layout.addWidget(self.pause_all_btn)

        self.stop_all_btn = QPushButton("ğŸ›‘ å…¨éƒ¨åœæ­¢")
        self.stop_all_btn.clicked.connect(self.stop_all_cameras)
        self.stop_all_btn.setEnabled(False)
        btn_layout.addWidget(self.stop_all_btn)

        self.clear_all_btn = QPushButton("ğŸ—‘ï¸ å…¨éƒ¨æ¸…é™¤")
        self.clear_all_btn.clicked.connect(self.clear_all_cameras)
        self.clear_all_btn.setEnabled(False)
        btn_layout.addWidget(self.clear_all_btn)

        center_panel.addLayout(btn_layout)
        control_layout.addLayout(center_panel, stretch=4)

        # å³ä¾§åŒºåŸŸï¼šçŠ¶æ€ä¿¡æ¯
        right_panel = QVBoxLayout()

        # ç³»ç»Ÿæ—¶é—´æ˜¾ç¤º
        self.time_label = QLabel()
        self.time_label.setAlignment(Qt.AlignRight)
        self.update_time()
        right_panel.addWidget(self.time_label)

        # æ£€æµ‹ç»Ÿè®¡
        stats_layout = QHBoxLayout()
        stats_layout.addWidget(QLabel("æ£€æµ‹ç»Ÿè®¡:"))

        self.fall_label = QLabel("æ‘”å€’: 0")
        self.walk_label = QLabel("è¡Œèµ°: 0")
        self.sit_label = QLabel("åä¸‹: 0")

        stats_layout.addWidget(self.fall_label)
        stats_layout.addWidget(self.walk_label)
        stats_layout.addWidget(self.sit_label)
        right_panel.addLayout(stats_layout)

        control_layout.addLayout(right_panel)

        parent_layout.addWidget(control_group)

    def init_monitor_area(self, parent_layout):
        """åˆå§‹åŒ–ç›‘æ§æ˜¾ç¤ºåŒºåŸŸ"""
        self.monitor_scroll = QScrollArea()
        self.monitor_scroll.setStyleSheet("""
            QScrollArea {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 rgba(236, 240, 241, 0.9),
                    stop:1 rgba(189, 195, 199, 0.9));
                border-radius: 8px;
            }
            QScrollArea > QWidget > QWidget {
                background: transparent;
            }
            QScrollArea::corner {
                background: transparent;
            }
        """)

        self.monitor_widget = QWidget()
        self.monitor_layout = QGridLayout(self.monitor_widget)
        self.monitor_scroll.setWidget(self.monitor_widget)
        self.monitor_scroll.setWidgetResizable(True)

        parent_layout.addWidget(self.monitor_scroll)

    def init_model_combo(self):
        """åˆå§‹åŒ–æ¨¡å‹ä¸‹æ‹‰æ¡†"""
        self.model_combo.clear()
        models = self.model_manager.scan_models()

        if not models:
            self.model_combo.addItem("æ— å¯ç”¨æ¨¡å‹")
            self.model_combo.setEnabled(False)
        else:
            self.model_combo.addItems([model['name'] for model in models])
            self.model_combo.setEnabled(True)
            self.try_load_default_model()

    def try_load_default_model(self):
        """å°è¯•åŠ è½½é»˜è®¤æ¨¡å‹"""
        if self.model_combo.count() > 0 and self.model_combo.itemText(0) != "æ— å¯ç”¨æ¨¡å‹":
            first_model = self.model_combo.itemText(0)
            self.load_model_by_name(first_model)

    def load_model_by_name(self, model_name):
        """æ ¹æ®åç§°åŠ è½½æ¨¡å‹"""
        models = self.model_manager.scan_models()
        for model in models:
            if model['name'] == model_name:
                self.load_model(model['path'])
                break

    def on_model_changed(self, model_text):
        """æ¨¡å‹é€‰æ‹©æ”¹å˜"""
        if model_text != "æ— å¯ç”¨æ¨¡å‹":
            self.load_model_by_name(model_text)

    def load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        try:
            self.current_model = YOLO(model_path)
            self.start_all_btn.setEnabled(True)
            return True
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def select_model(self):
        """é€‰æ‹©æ¨¡å‹"""
        dialog = ModelSelectionDialog(self.model_manager, self)
        if dialog.exec() == QDialog.Accepted and dialog.selected_model:
            try:
                self.current_model = YOLO(dialog.selected_model)
                model_name = Path(dialog.selected_model).name
                self.model_combo.clear()
                self.model_combo.addItem(model_name)
                self.start_all_btn.setEnabled(True)
                QMessageBox.information(self, "æˆåŠŸ", f"æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
            except Exception as e:
                QMessageBox.critical(self, "é”™è¯¯", f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

    def refresh_cameras(self):
        """åˆ·æ–°æ‘„åƒå¤´åˆ—è¡¨"""
        self.camera_manager.scan_cameras()
        self.camera_list.clear()

        for camera in self.camera_manager.get_available_cameras():
            item = QListWidgetItem(f"ğŸ“¹ {camera['name']} ({camera['resolution']})")
            item.setData(Qt.UserRole, camera['id'])
            self.camera_list.addItem(item)

    def start_all_cameras(self):
        """å¯åŠ¨æ‰€æœ‰é€‰ä¸­çš„æ‘„åƒå¤´"""
        if not self.current_model:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹")
            return

        selected_items = self.camera_list.selectedItems()
        if not selected_items:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ‘„åƒå¤´")
            return

        camera_ids = [item.data(Qt.UserRole) for item in selected_items]
        self.clear_monitor_display()

        # æ ¹æ®æ‘„åƒå¤´æ•°é‡è®¾ç½®å¸ƒå±€
        self.setup_grid_layout(len(camera_ids))

        for cam_id in camera_ids:
            self.add_camera_widget(cam_id)
            self.start_camera_thread(cam_id)

        self.start_all_btn.setEnabled(False)
        self.pause_all_btn.setEnabled(True)
        self.stop_all_btn.setEnabled(True)
        self.clear_all_btn.setEnabled(True)

    def setup_grid_layout(self, num_cameras):
        """æ ¹æ®æ‘„åƒå¤´æ•°é‡è®¾ç½®ç½‘æ ¼å¸ƒå±€"""
        # æ¸…é™¤ç°æœ‰å¸ƒå±€
        for i in reversed(range(self.monitor_layout.count())):
            widget = self.monitor_layout.itemAt(i).widget()
            if widget:
                widget.setParent(None)

        # è®¾ç½®æ–°çš„ç½‘æ ¼å¸ƒå±€
        if num_cameras == 1:
            rows, cols = 1, 1
        elif num_cameras == 2:
            rows, cols = 1, 2
        elif num_cameras == 3:
            rows, cols = 2, 2  # 3ä¸ªæ‘„åƒå¤´æ—¶ä½¿ç”¨2x2ç½‘æ ¼ï¼Œæœ€åä¸€ä¸ªä½ç½®ç•™ç©º
        else:  # 4ä¸ªæˆ–æ›´å¤š
            rows, cols = 2, 2

        # è®¾ç½®è¡Œåˆ—ä¼¸ç¼©
        for r in range(rows):
            self.monitor_layout.setRowStretch(r, 1)
        for c in range(cols):
            self.monitor_layout.setColumnStretch(c, 1)

    def add_camera_widget(self, camera_id):
        """ä¸ºæ‘„åƒå¤´æ·»åŠ æ˜¾ç¤ºå’Œæ§åˆ¶éƒ¨ä»¶"""
        camera_group = QGroupBox(f"ğŸ“¹ æ‘„åƒå¤´ {camera_id}")
        camera_group.setStyleSheet("""
            QGroupBox {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                    stop:0 rgba(248, 249, 250, 0.9), stop:1 rgba(233, 236, 239, 0.9));
                color: #7f8c8d;
                font-weight: bold;
                font-size: 14px;
                border-radius: 10px;
            }
        """)

        layout = QVBoxLayout(camera_group)

        # å›¾åƒæ˜¾ç¤ºåŒºåŸŸ
        image_label = QLabel("ç­‰å¾…è¿æ¥...")
        image_label.setAlignment(Qt.AlignCenter)
        image_label.setStyleSheet("background-color: #ecf0f1;")
        layout.addWidget(image_label)

        # çŠ¶æ€æ ‡ç­¾
        status_label = QLabel("çŠ¶æ€: åˆå§‹åŒ–ä¸­...")
        status_label.setStyleSheet("color: #7f8c8d; font-size: 10px;")
        layout.addWidget(status_label)

        # æ§åˆ¶æŒ‰é’®
        btn_layout = QHBoxLayout()

        start_btn = QPushButton("â–¶ï¸ å¼€å§‹")
        start_btn.clicked.connect(lambda: self.start_camera(camera_id))
        btn_layout.addWidget(start_btn)

        pause_btn = QPushButton("â¸ï¸ æš‚åœ")
        pause_btn.clicked.connect(lambda: self.pause_camera(camera_id))
        pause_btn.setEnabled(False)
        btn_layout.addWidget(pause_btn)

        stop_btn = QPushButton("ğŸ›‘ åœæ­¢")
        stop_btn.clicked.connect(lambda: self.stop_camera(camera_id))
        stop_btn.setEnabled(False)
        btn_layout.addWidget(stop_btn)

        layout.addLayout(btn_layout)

        # æ·»åŠ åˆ°å¸ƒå±€
        position = self.get_next_grid_position()
        self.monitor_layout.addWidget(camera_group, position[0], position[1])

        # ä¿å­˜æ§ä»¶å¼•ç”¨
        self.camera_widgets[camera_id] = {
            'group': camera_group,
            'image': image_label,
            'status': status_label,
            'start_btn': start_btn,
            'pause_btn': pause_btn,
            'stop_btn': stop_btn,
            'running': False,
            'paused': False
        }

    def get_next_grid_position(self):
        """è·å–ä¸‹ä¸€ä¸ªç½‘æ ¼ä½ç½®"""
        count = len(self.camera_widgets)
        if count == 0:
            return (0, 0)
        elif count == 1:
            return (0, 1)
        elif count == 2:
            return (1, 0)
        elif count == 3:
            return (1, 1)
        else:
            # è¶…è¿‡4ä¸ªæ—¶å¾ªç¯ä½¿ç”¨ä½ç½®
            row = (count // 2) % 2
            col = count % 2
            return (row, col)

    def start_camera_thread(self, camera_id):
        """å¯åŠ¨æ‘„åƒå¤´çº¿ç¨‹"""
        if camera_id in self.camera_widgets and camera_id not in self.camera_threads:
            thread = CameraThread(camera_id, self.current_model)
            thread.frame_ready.connect(self.update_camera_display)
            thread.finished.connect(lambda: self.on_camera_thread_finished(camera_id))
            self.camera_threads[camera_id] = thread
            thread.start()
            self.start_camera(camera_id)

    def start_camera(self, camera_id):
        """å¯åŠ¨å•ä¸ªæ‘„åƒå¤´"""
        if camera_id in self.camera_widgets:
            self.camera_widgets[camera_id]['status'].setText("çŠ¶æ€: è¿è¡Œä¸­")
            self.camera_widgets[camera_id]['start_btn'].setEnabled(False)
            self.camera_widgets[camera_id]['pause_btn'].setEnabled(True)
            self.camera_widgets[camera_id]['stop_btn'].setEnabled(True)
            self.camera_widgets[camera_id]['running'] = True
            self.camera_widgets[camera_id]['paused'] = False

    def pause_camera(self, camera_id):
        """æš‚åœ/ç»§ç»­å•ä¸ªæ‘„åƒå¤´"""
        if camera_id in self.camera_widgets and camera_id in self.camera_threads:
            widget = self.camera_widgets[camera_id]
            thread = self.camera_threads[camera_id]

            if widget['paused']:
                # æ¢å¤
                thread.resume()
                widget['status'].setText("çŠ¶æ€: è¿è¡Œä¸­")
                widget['pause_btn'].setText("â¸ï¸ æš‚åœ")
                widget['paused'] = False
            else:
                # æš‚åœ
                thread.pause()
                widget['status'].setText("çŠ¶æ€: å·²æš‚åœ")
                widget['pause_btn'].setText("â–¶ï¸ ç»§ç»­")
                widget['paused'] = True

    def stop_camera(self, camera_id):
        """åœæ­¢å•ä¸ªæ‘„åƒå¤´"""
        if camera_id in self.camera_threads:
            self.camera_threads[camera_id].stop()
            self.camera_threads[camera_id].wait()
            del self.camera_threads[camera_id]

        if camera_id in self.camera_widgets:
            self.camera_widgets[camera_id]['status'].setText("çŠ¶æ€: å·²åœæ­¢")
            self.camera_widgets[camera_id]['start_btn'].setEnabled(True)
            self.camera_widgets[camera_id]['pause_btn'].setEnabled(False)
            self.camera_widgets[camera_id]['stop_btn'].setEnabled(False)
            self.camera_widgets[camera_id]['running'] = False
            self.camera_widgets[camera_id]['paused'] = False

    def on_camera_thread_finished(self, camera_id):
        """æ‘„åƒå¤´çº¿ç¨‹ç»“æŸæ—¶çš„å¤„ç†"""
        if camera_id in self.camera_threads:
            del self.camera_threads[camera_id]

        if camera_id in self.camera_widgets:
            self.camera_widgets[camera_id]['status'].setText("çŠ¶æ€: å·²åœæ­¢")
            self.camera_widgets[camera_id]['start_btn'].setEnabled(True)
            self.camera_widgets[camera_id]['pause_btn'].setEnabled(False)
            self.camera_widgets[camera_id]['stop_btn'].setEnabled(False)
            self.camera_widgets[camera_id]['running'] = False
            self.camera_widgets[camera_id]['paused'] = False

    def pause_all_cameras(self):
        """æš‚åœ/ç»§ç»­æ‰€æœ‰æ‘„åƒå¤´"""
        if any(w['running'] for w in self.camera_widgets.values()):
            all_paused = all(w['paused'] for w in self.camera_widgets.values() if w['running'])

            for cam_id, widget in self.camera_widgets.items():
                if widget['running']:
                    if all_paused:
                        # å…¨éƒ¨æ¢å¤
                        self.pause_camera(cam_id)
                        self.pause_all_btn.setText("â¸ï¸ å…¨éƒ¨æš‚åœ")
                    else:
                        # å…¨éƒ¨æš‚åœ
                        if not widget['paused']:
                            self.pause_camera(cam_id)
                        self.pause_all_btn.setText("â–¶ï¸ å…¨éƒ¨ç»§ç»­")

    def stop_all_cameras(self):
        """åœæ­¢æ‰€æœ‰æ‘„åƒå¤´"""
        for cam_id in list(self.camera_threads.keys()):
            self.stop_camera(cam_id)

        self.start_all_btn.setEnabled(True)
        self.pause_all_btn.setEnabled(False)
        self.stop_all_btn.setEnabled(False)

    def clear_all_cameras(self):
        """æ¸…é™¤æ‰€æœ‰æ‘„åƒå¤´"""
        self.stop_all_cameras()
        self.clear_monitor_display()
        self.start_all_btn.setEnabled(True)
        self.clear_all_btn.setEnabled(False)
        self.detection_stats = {0: 0, 1: 0, 2: 0}
        self.update_stats()

    def clear_monitor_display(self):
        """æ¸…ç©ºç›‘æ§æ˜¾ç¤º"""
        for cam_id in list(self.camera_widgets.keys()):
            self.camera_widgets[cam_id]['group'].deleteLater()
        self.camera_widgets.clear()

    def update_time(self):
        """æ›´æ–°æ—¶é—´æ˜¾ç¤º"""
        current_time = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
        self.time_label.setText(f"ğŸ•’ ç³»ç»Ÿæ—¶é—´: {current_time}")

    def update_stats(self):
        """æ›´æ–°æ£€æµ‹ç»Ÿè®¡"""
        self.fall_label.setText(f"æ‘”å€’: {self.detection_stats[0]}")
        self.walk_label.setText(f"è¡Œèµ°: {self.detection_stats[1]}")
        self.sit_label.setText(f"åä¸‹: {self.detection_stats[2]}")

    @Slot(int, np.ndarray, str, int)
    def update_camera_display(self, camera_id, image, status, detection_result):
        """æ›´æ–°æ‘„åƒå¤´æ˜¾ç¤º"""
        if camera_id in self.camera_widgets:
            # æ˜¾ç¤ºå›¾åƒ
            if image is not None:
                height, width, channel = image.shape
                bytes_per_line = 3 * width
                q_image = QImage(image.data, width, height, bytes_per_line, QImage.Format_RGB888)
                pixmap = QPixmap.fromImage(q_image)
                self.camera_widgets[camera_id]['image'].setPixmap(
                    pixmap.scaled(self.camera_widgets[camera_id]['image'].size(),
                                  Qt.KeepAspectRatio, Qt.SmoothTransformation)
                )

            # æ›´æ–°çŠ¶æ€
            if status:
                self.camera_widgets[camera_id]['status'].setText(status)

            # æ›´æ–°æ£€æµ‹ç»Ÿè®¡
            if detection_result in self.detection_stats:
                self.detection_stats[detection_result] += 1
                self.update_stats()
class SliceDetailDialog(QDialog):
        """åˆ‡ç‰‡è¯¦ç»†ä¿¡æ¯å¼¹çª—"""

        def __init__(self, nii_data, slice_index, direction, parent=None):
            super().__init__(parent)
            self.nii_data = nii_data
            self.current_slice_index = slice_index
            self.direction = direction
            self.max_slices = nii_data.shape[direction]

            self.init_ui()
            self.update_slice_display()
            # å¯ç”¨é¼ æ ‡è·Ÿè¸ªä»¥æ•è·æ»šè½®äº‹ä»¶
            self.setMouseTracking(True)

        def init_ui(self):
            self.setWindowTitle(f"åˆ‡ç‰‡è¯¦ç»†ä¿¡æ¯ - Slice {self.current_slice_index}")
            self.resize(600, 600)

            layout = QVBoxLayout(self)

            # å›¾åƒæ˜¾ç¤ºåŒºåŸŸ
            self.image_label = QLabel()
            self.image_label.setAlignment(Qt.AlignCenter)
            self.image_label.setMinimumSize(400, 400)
            # å¯ç”¨å›¾åƒæ ‡ç­¾çš„é¼ æ ‡äº‹ä»¶
            self.image_label.setMouseTracking(True)
            self.image_label.installEventFilter(self)  # å®‰è£…äº‹ä»¶è¿‡æ»¤å™¨
            layout.addWidget(self.image_label)

            # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
            button_layout = QHBoxLayout()

            self.prev_button = QPushButton("â¬†ï¸ ä¸Šä¸€å¼ ")
            self.prev_button.clicked.connect(self.show_previous_slice)
            button_layout.addWidget(self.prev_button)

            self.slice_info_label = QLabel(f"Slice {self.current_slice_index}/{self.max_slices - 1}")
            self.slice_info_label.setAlignment(Qt.AlignCenter)
            button_layout.addWidget(self.slice_info_label)

            self.next_button = QPushButton("â¬‡ï¸ ä¸‹ä¸€å¼ ")
            self.next_button.clicked.connect(self.show_next_slice)
            button_layout.addWidget(self.next_button)

            layout.addLayout(button_layout)

            # å…³é—­æŒ‰é’®
            close_button = QPushButton("å…³é—­")
            close_button.clicked.connect(self.accept)
            layout.addWidget(close_button)

            # æ›´æ–°æŒ‰é’®çŠ¶æ€
            self.update_button_states()
        def eventFilter(self, obj, event):
            """äº‹ä»¶è¿‡æ»¤å™¨ï¼Œç”¨äºå¤„ç†é¼ æ ‡æ»šè½®äº‹ä»¶"""
            if obj == self.image_label and event.type() == QEvent.Wheel:
                if event.angleDelta().y() > 0:  # å‘ä¸Šæ»šåŠ¨
                    self.show_previous_slice()
                else:  # å‘ä¸‹æ»šåŠ¨
                    self.show_next_slice()
                return True
            return super().eventFilter(obj, event)
        def update_slice_display(self):
            """æ›´æ–°åˆ‡ç‰‡æ˜¾ç¤º"""
            try:
                # æå–åˆ‡ç‰‡æ•°æ®
                if self.direction == 0:  # Sagittal
                    slice_data = self.nii_data[self.current_slice_index, :, :]
                elif self.direction == 1:  # Coronal
                    slice_data = self.nii_data[:, self.current_slice_index, :]
                else:  # Axial
                    slice_data = self.nii_data[:, :, self.current_slice_index]

                # ç¡®ä¿æ•°æ®æ˜¯è¿ç»­çš„
                if not slice_data.flags['C_CONTIGUOUS']:
                    slice_data = np.ascontiguousarray(slice_data)

                # è½¬æ¢ä¸º QImage æ˜¾ç¤º
                # å½’ä¸€åŒ–æ•°æ®åˆ° 0-255 èŒƒå›´
                slice_normalized = ((slice_data - slice_data.min()) /
                                    (slice_data.max() - slice_data.min()) * 255).astype(np.uint8)

                height, width = slice_normalized.shape
                bytes_per_line = width
                q_img = QImage(slice_normalized.data, width, height, bytes_per_line, QImage.Format_Grayscale8)

                # ç¼©æ”¾å›¾åƒä»¥é€‚åº”æ˜¾ç¤ºåŒºåŸŸ
                pixmap = QPixmap.fromImage(q_img)
                scaled_pixmap = pixmap.scaled(
                    self.image_label.size(),
                    Qt.KeepAspectRatio,
                    Qt.SmoothTransformation
                )
                self.image_label.setPixmap(scaled_pixmap)

                # æ›´æ–°åˆ‡ç‰‡ä¿¡æ¯
                self.slice_info_label.setText(f"Slice {self.current_slice_index}/{self.max_slices - 1}")

                # æ›´æ–°æŒ‰é’®çŠ¶æ€
                self.update_button_states()

            except Exception as e:
                self.image_label.setText(f"æ˜¾ç¤ºé”™è¯¯: {str(e)}")

        def update_button_states(self):
            """æ›´æ–°æŒ‰é’®çŠ¶æ€"""
            self.prev_button.setEnabled(bool(self.current_slice_index > 0))
            self.next_button.setEnabled(bool(self.current_slice_index < self.max_slices - 1))

        def show_previous_slice(self):
            """æ˜¾ç¤ºä¸Šä¸€å¼ åˆ‡ç‰‡"""
            if self.current_slice_index > 0:
                self.current_slice_index -= 1
                self.update_slice_display()

        def show_next_slice(self):
            """æ˜¾ç¤ºä¸‹ä¸€å¼ åˆ‡ç‰‡"""
            if self.current_slice_index < self.max_slices - 1:
                self.current_slice_index += 1
                self.update_slice_display()


class SnapshotWidget(QWidget):
    """ç›‘æ§å¿«ç…§ç»„ä»¶ - ç”¨äºæ˜¾ç¤ºå’Œå›æ”¾å·²ä¿å­˜çš„ç›‘æ§å¿«ç…§"""

    def __init__(self, parent=None):
        super().__init__(parent)
        self.snapshots = []  # å­˜å‚¨å¿«ç…§è®°å½•
        self.current_snapshot_index = 0
        self.monitor_history_dir = Path("monitor_history")
        self.monitor_history_dir.mkdir(exist_ok=True)
        # æ·»åŠ detection_historyç›®å½•æ”¯æŒ
        self.detection_history_dir = Path("detection_history")
        self.detection_history_dir.mkdir(exist_ok=True)

        self.init_ui()
        self.load_snapshots()

    def init_ui(self):
        """åˆå§‹åŒ–UIç•Œé¢"""
        layout = QVBoxLayout(self)

        # å¿«ç…§åˆ—è¡¨å’Œæ’­æ”¾åŒºåŸŸ
        content_layout = QHBoxLayout()

        # å·¦ä¾§ï¼šå¿«ç…§åˆ—è¡¨
        left_panel = QVBoxLayout()

        list_group = QGroupBox("ğŸ“‹ å¿«ç…§å†å²")
        list_group.setMaximumHeight(780)
        list_layout = QVBoxLayout(list_group)

        self.snapshot_list = QListWidget()
        self.snapshot_list.itemClicked.connect(self.on_snapshot_selected)
        list_layout.addWidget(self.snapshot_list)

        # å¿«ç…§æ“ä½œæŒ‰é’®
        snapshot_btn_layout = QHBoxLayout()

        self.play_btn = QPushButton("â–¶ï¸ æ’­æ”¾")
        self.play_btn.clicked.connect(self.play_selected_snapshot)
        self.play_btn.setEnabled(False)
        snapshot_btn_layout.addWidget(self.play_btn)

        self.delete_btn = QPushButton("ğŸ—‘ï¸ åˆ é™¤")
        self.delete_btn.clicked.connect(self.delete_selected_snapshot)
        self.delete_btn.setEnabled(False)
        snapshot_btn_layout.addWidget(self.delete_btn)

        self.refresh_btn = QPushButton("ğŸ”„ åˆ·æ–°")
        self.refresh_btn.clicked.connect(self.load_snapshots)
        snapshot_btn_layout.addWidget(self.refresh_btn)

        # æ·»åŠ å¯¼å‡ºæŒ‰é’®åˆ°å¸ƒå±€ä¸­
        self.export_btn = QPushButton("ğŸ“¤ å¯¼å‡º")
        self.export_btn.clicked.connect(self.export_selected_snapshot)
        self.export_btn.setEnabled(False)
        snapshot_btn_layout.addWidget(self.export_btn)

        list_layout.addLayout(snapshot_btn_layout)
        left_panel.addWidget(list_group)

        content_layout.addLayout(left_panel, 1)

        # å³ä¾§ï¼šæ’­æ”¾åŒºåŸŸ
        right_panel = QVBoxLayout()

        player_group = QGroupBox("ğŸ¥ å¿«ç…§æ’­æ”¾å™¨")
        # player_group.setMaximumHeight(780)  # å‡å°‘é«˜åº¦
        player_layout = QVBoxLayout(player_group)

        # è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
        self.video_label = QLabel("é€‰æ‹©å¿«ç…§è¿›è¡Œæ’­æ”¾")
        self.video_label.setMinimumSize(640, 390)
        self.video_label.setStyleSheet("""
            QLabel {
                border: 1px solid rgba(52, 152, 219, 0.3);
                font-size: 14px;
                border-radius: 10px;
            }
        """)
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setScaledContents(True)
        player_layout.addWidget(self.video_label)

        # æ’­æ”¾æ§åˆ¶
        playback_layout = QHBoxLayout()

        self.playback_btn = QPushButton("â–¶ï¸")
        self.playback_btn.clicked.connect(self.toggle_playback)
        self.playback_btn.setEnabled(False)
        playback_layout.addWidget(self.playback_btn)

        self.stop_btn = QPushButton("â¹ï¸")
        self.stop_btn.clicked.connect(self.stop_playback)
        self.stop_btn.setEnabled(False)
        playback_layout.addWidget(self.stop_btn)

        # è¿›åº¦æ¡
        self.progress_slider = QSlider(Qt.Horizontal)
        self.progress_slider.setEnabled(False)
        self.progress_slider.valueChanged.connect(self.on_progress_changed)
        playback_layout.addWidget(self.progress_slider)

        # æ—¶é—´æ˜¾ç¤º
        self.time_label = QLabel("00:00 / 00:00")
        self.time_label.setStyleSheet("color: #7f8c8d; font-size: 12px;")
        playback_layout.addWidget(self.time_label)

        player_layout.addLayout(playback_layout, stretch=5)

        # å¿«ç…§ä¿¡æ¯
        info_group = QGroupBox("ğŸ“Š å¿«ç…§ä¿¡æ¯")
        info_group.setStyleSheet("""
                    QGroupBox {
                border: 1px solid rgba(52, 152, 219, 0.3);
                font-size: 14px;
                border-radius: 10px;
            }
        """
                                 )
        info_layout = QVBoxLayout(info_group)

        self.info_text = QTextEdit()
        self.info_text.setMinimumHeight(170)
        self.info_text.setReadOnly(True)
        self.info_text.setStyleSheet("""
            QTextEdit {
                background: rgba(248, 249, 250, 0.8);
                border: 1px solid rgba(189, 195, 199, 0.3);
                border-radius: 5px;
                font-size: 11px;
                color: #2c3e50;
            }
        """)
        info_layout.addWidget(self.info_text)

        player_layout.addWidget(info_group, stretch=3)
        right_panel.addWidget(player_group)

        content_layout.addLayout(right_panel, 2)
        layout.addLayout(content_layout)

        # åˆå§‹åŒ–æ’­æ”¾å®šæ—¶å™¨
        self.playback_timer = QTimer()
        self.playback_timer.timeout.connect(self.update_playback)
        self.current_frame_index = 0
        self.is_playing = False

    def toggle_recording(self):
        """åˆ‡æ¢å½•åˆ¶çŠ¶æ€"""
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()

    def start_recording(self):
        """å¼€å§‹å½•åˆ¶"""
        self.is_recording = True
        self.recording_frames.clear()
        self.recording_start_time = time.time()
        self.max_recording_duration = self.duration_spinbox.value()

        self.record_btn.setText("â¹ï¸ åœæ­¢å½•åˆ¶")
        self.record_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #95a5a6, stop:1 #7f8c8d);
                color: white;
                border: none;
                border-radius: 8px;
                padding: 10px 20px;
                font-size: 14px;
                font-weight: bold;
            }
            QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #7f8c8d, stop:1 #6c7b7d);
            }
        """)
        self.save_btn.setEnabled(False)
        self.clear_btn.setEnabled(True)
        self.recording_status.setText("çŠ¶æ€: å½•åˆ¶ä¸­...")
        self.recording_status.setStyleSheet("""
            QLabel {
                color: #e74c3c;
                font-size: 12px;
                padding: 5px;
                background: rgba(231, 76, 60, 0.1);
                border-radius: 5px;
            }
        """)

    def stop_recording(self):
        """åœæ­¢å½•åˆ¶"""
        self.is_recording = False

        self.record_btn.setText("ğŸ”´ å¼€å§‹å½•åˆ¶")
        self.record_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #e74c3c, stop:1 #c0392b);
                color: white;
                border: none;
                border-radius: 8px;
                padding: 10px 20px;
                font-size: 14px;
                font-weight: bold;
            }
            QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #c0392b, stop:1 #a93226);
            }
        """)

        if len(self.recording_frames) > 0:
            self.save_btn.setEnabled(True)

        self.recording_status.setText(f"çŠ¶æ€: å½•åˆ¶å®Œæˆ ({len(self.recording_frames)} å¸§)")
        self.recording_status.setStyleSheet("""
            QLabel {
                color: #27ae60;
                font-size: 12px;
                padding: 5px;
                background: rgba(39, 174, 96, 0.1);
                border-radius: 5px;
            }
        """)

    def add_frame(self, frame, detection_info=None):
        """æ·»åŠ å¸§åˆ°å½•åˆ¶ä¸­"""
        if not self.is_recording:
            return

        # æ£€æŸ¥å½•åˆ¶æ—¶é•¿
        if time.time() - self.recording_start_time > self.max_recording_duration:
            self.stop_recording()
            return

        frame_data = {
            'frame': frame.copy(),
            'timestamp': time.time(),
            'detection_info': detection_info or {}
        }
        self.recording_frames.append(frame_data)

        # æ›´æ–°çŠ¶æ€
        elapsed = time.time() - self.recording_start_time
        self.recording_status.setText(f"çŠ¶æ€: å½•åˆ¶ä¸­... ({len(self.recording_frames)} å¸§, {elapsed:.1f}s)")

    def save_current_recording(self):
        """ä¿å­˜å½“å‰å½•åˆ¶"""
        if not self.recording_frames:
            QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„å½•åˆ¶å†…å®¹")
            return

        # ç”Ÿæˆå¿«ç…§ID
        snapshot_id = f"snapshot_{int(time.time())}"
        snapshot_path = self.snapshots_dir / f"{snapshot_id}.json"

        # ä¿å­˜å¸§æ•°æ®
        snapshot_data = {
            'id': snapshot_id,
            'created_time': time.time(),
            'duration': self.max_recording_duration,
            'fps': self.fps_spinbox.value(),
            'frame_count': len(self.recording_frames),
            'frames': []
        }

        # å‹ç¼©ä¿å­˜å¸§æ•°æ®
        for i, frame_data in enumerate(self.recording_frames):
            # å°†å¸§è½¬æ¢ä¸ºbase64ç¼–ç çš„å­—ç¬¦ä¸²
            _, buffer = cv2.imencode('.jpg', frame_data['frame'], [cv2.IMWRITE_JPEG_QUALITY, 80])
            frame_str = buffer.tobytes().hex()

            snapshot_data['frames'].append({
                'index': i,
                'timestamp': frame_data['timestamp'],
                'frame_data': frame_str,
                'detection_info': frame_data['detection_info']
            })

        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(snapshot_path, 'w', encoding='utf-8') as f:
            json.dump(snapshot_data, f, ensure_ascii=False, indent=2)

        # æ·»åŠ åˆ°å¿«ç…§åˆ—è¡¨
        snapshot_info = {
            'id': snapshot_id,
            'path': str(snapshot_path),
            'created_time': snapshot_data['created_time'],
            'duration': snapshot_data['duration'],
            'frame_count': snapshot_data['frame_count'],
            'fps': snapshot_data['fps']
        }

        self.snapshots.append(snapshot_info)
        self.update_snapshot_list()

        QMessageBox.information(self, "æˆåŠŸ", f"å¿«ç…§å·²ä¿å­˜: {snapshot_id}")

        # æ¸…ç©ºå½“å‰å½•åˆ¶
        self.clear_recording()

    def clear_recording(self):
        """æ¸…ç©ºå½“å‰å½•åˆ¶"""
        self.recording_frames.clear()
        self.save_btn.setEnabled(False)
        self.clear_btn.setEnabled(False)
        self.recording_status.setText("çŠ¶æ€: æœªå½•åˆ¶")
        self.recording_status.setStyleSheet("""
            QLabel {
                color: #7f8c8d;
                font-size: 12px;
                padding: 5px;
                background: rgba(236, 240, 241, 0.5);
                border-radius: 5px;
            }
        """)

    def load_snapshots(self):
        """åŠ è½½å·²ä¿å­˜çš„å¿«ç…§"""
        self.snapshots.clear()

        # æ‰«æmonitor_historyç›®å½•ä¸‹çš„JSONæ–‡ä»¶
        for json_file in self.monitor_history_dir.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # æ£€æŸ¥å¯¹åº”çš„MP4æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                mp4_file = json_file.with_suffix('.mp4')
                if mp4_file.exists():
                    snapshot_info = {
                        'camera_name': data.get('camera_name', 'æœªçŸ¥æ‘„åƒå¤´'),
                        'start_time': data.get('start_time', 0),
                        'end_time': data.get('end_time', 0),
                        'file_size': self._get_file_size(mp4_file),
                        'detection_stats': data.get('detection_stats', {}),
                        'json_path': str(json_file),
                        'mp4_path': str(mp4_file),
                        'fps': data.get('fps', 20),
                        'total_detections': data.get('total_detections', 0),
                        'source': 'monitor'  # æ ‡è®°æ¥æºä¸ºç›‘æ§
                    }
                    self.snapshots.append(snapshot_info)
            except Exception as e:
                print(f"åŠ è½½å¿«ç…§å¤±è´¥ {json_file}: {e}")

        # æ‰«ædetection_historyç›®å½•ä¸‹çš„JSONæ–‡ä»¶
        for json_file in self.detection_history_dir.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # æ£€æŸ¥å¯¹åº”çš„MP4æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                mp4_file = json_file.with_suffix('.mp4')
                if mp4_file.exists():
                    snapshot_info = {
                        'camera_name': data.get('source_name', 'æœªçŸ¥æº'),
                        'start_time': data.get('start_time', 0),
                        'end_time': data.get('end_time', 0),
                        'file_size': self._get_file_size(mp4_file),
                        'detection_stats': data.get('detection_stats', {}),
                        'json_path': str(json_file),
                        'mp4_path': str(mp4_file),
                        'fps': data.get('fps', 20),
                        'total_detections': data.get('total_detections', 0),
                        'source': 'detection'  # æ ‡è®°æ¥æºä¸ºæ£€æµ‹
                    }
                    self.snapshots.append(snapshot_info)
            except Exception as e:
                print(f"åŠ è½½å¿«ç…§å¤±è´¥ {json_file}: {e}")

        self.update_snapshot_list()

    def _get_file_size(self, file_path):
        """è·å–æ–‡ä»¶å¤§å°"""
        try:
            size = file_path.stat().st_size
            for unit in ['B', 'KB', 'MB', 'GB']:
                if size < 1024.0:
                    return f"{size:.1f} {unit}"
                size /= 1024.0
            return f"{size:.1f} TB"
        except:
            return "Unknown"

    def update_snapshot_list(self):
        """æ›´æ–°å¿«ç…§åˆ—è¡¨æ˜¾ç¤º"""
        self.snapshot_list.clear()

        # æŒ‰å¼€å§‹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        self.snapshots.sort(key=lambda x: x['start_time'], reverse=True)

        for snapshot in self.snapshots:
            start_time = datetime.fromtimestamp(snapshot['start_time'])
            end_time = datetime.fromtimestamp(snapshot['end_time'])

            # æ ¼å¼åŒ–æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯
            stats_text = ""
            if snapshot['detection_stats']:
                stats_items = []
                for class_name, count in snapshot['detection_stats'].items():
                    stats_items.append(f"{class_name}:{count}")
                stats_text = " | ".join(stats_items)

            # æ ¹æ®æ¥æºæ·»åŠ ä¸åŒçš„å‰ç¼€æ ‡è¯†
            source_prefix = "ğŸ–¥ï¸" if snapshot['source'] == 'monitor' else "ğŸ“¹"
            item_text = f"{source_prefix} {snapshot['camera_name']}\n"
            item_text += f"æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
            item_text += f"æ–‡ä»¶å¤§å°: {snapshot['file_size']} | æ£€æµ‹æ¬¡æ•°: {snapshot['total_detections']}\n"
            if stats_text:
                item_text += f"æ£€æµ‹ç»Ÿè®¡: {stats_text}"

            item = QListWidgetItem(item_text)
            item.setData(Qt.UserRole, snapshot)
            self.snapshot_list.addItem(item)

    def on_snapshot_selected(self, item):
        """å¿«ç…§è¢«é€‰ä¸­"""
        snapshot = item.data(Qt.UserRole)
        self.current_snapshot_index = self.snapshots.index(snapshot)
        self.play_btn.setEnabled(True)
        # self.playback_btn.setEnabled(True)
        self.delete_btn.setEnabled(True)
        self.export_btn.setEnabled(True)

        # æ˜¾ç¤ºå¿«ç…§ä¿¡æ¯
        self.show_snapshot_info(snapshot)

    def show_snapshot_info(self, snapshot):
        """æ˜¾ç¤ºå¿«ç…§ä¿¡æ¯"""
        start_time = datetime.fromtimestamp(snapshot['start_time'])
        end_time = datetime.fromtimestamp(snapshot['end_time'])
        duration = snapshot['end_time'] - snapshot['start_time']

        info_text = f"æ‘„åƒå¤´: {snapshot['camera_name']}\n"
        info_text += f"å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        info_text += f"ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        info_text += f"å½•åˆ¶æ—¶é•¿: {duration:.1f} ç§’\n"
        info_text += f"æ–‡ä»¶å¤§å°: {snapshot['file_size']}\n"
        info_text += f"å¸§ç‡: {snapshot['fps']} fps\n"
        info_text += f"æ£€æµ‹æ¬¡æ•°: {snapshot['total_detections']}\n"

        if snapshot['detection_stats']:
            info_text += f"æ£€æµ‹ç»Ÿè®¡:\n"
            for class_name, count in snapshot['detection_stats'].items():
                info_text += f"  {class_name}: {count} æ¬¡\n"

        info_text += f"è§†é¢‘æ–‡ä»¶: {snapshot['mp4_path']}"

        self.info_text.setText(info_text)

    def play_selected_snapshot(self):
        """æ’­æ”¾é€‰ä¸­çš„å¿«ç…§"""
        if not self.snapshots or self.current_snapshot_index >= len(self.snapshots):
            return

        snapshot = self.snapshots[self.current_snapshot_index]

        try:
            # ä½¿ç”¨OpenCVè¯»å–MP4æ–‡ä»¶
            cap = cv2.VideoCapture(snapshot['mp4_path'])
            if not cap.isOpened():
                QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
                return

            # è¯»å–æ‰€æœ‰å¸§
            self.playback_frames = []
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                self.playback_frames.append(frame)

            cap.release()

            if not self.playback_frames:
                QMessageBox.warning(self, "é”™è¯¯", "è§†é¢‘æ–‡ä»¶ä¸ºç©º")
                return

            # è®¾ç½®æ’­æ”¾å‚æ•°
            self.current_frame_index = 0
            self.playback_fps = snapshot['fps']
            self.playback_interval = 1000 // self.playback_fps  # æ¯«ç§’

            # è®¾ç½®è¿›åº¦æ¡
            self.progress_slider.setRange(0, len(self.playback_frames) - 1)
            self.progress_slider.setValue(0)
            self.progress_slider.setEnabled(True)
            self.playback_btn.setEnabled(True)

            # å¼€å§‹æ’­æ”¾
            self.toggle_playback()

        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"æ’­æ”¾å¿«ç…§å¤±è´¥: {str(e)}")

    def toggle_playback(self):
        """åˆ‡æ¢æ’­æ”¾çŠ¶æ€"""
        if not hasattr(self, 'playback_frames') or not self.playback_frames:
            return

        if self.is_playing:
            self.pause_playback()
        else:
            self.start_playback()

    def start_playback(self):
        """å¼€å§‹æ’­æ”¾"""
        self.is_playing = True
        self.playback_btn.setText("â¸ï¸")
        self.stop_btn.setEnabled(True)

        self.playback_timer.start(self.playback_interval)

    def pause_playback(self):
        """æš‚åœæ’­æ”¾"""
        self.is_playing = False
        self.playback_btn.setText("â–¶ï¸")

        self.playback_timer.stop()

    def stop_playback(self):
        """åœæ­¢æ’­æ”¾"""
        self.is_playing = False
        self.playback_btn.setText("â–¶ï¸")
        self.stop_btn.setEnabled(False)

        self.playback_timer.stop()
        self.current_frame_index = 0
        self.progress_slider.setValue(0)

        # æ˜¾ç¤ºç¬¬ä¸€å¸§
        if hasattr(self, 'playback_frames') and self.playback_frames:
            self.display_frame(self.playback_frames[0])

    def update_playback(self):
        """æ›´æ–°æ’­æ”¾"""
        if not hasattr(self, 'playback_frames') or not self.playback_frames:
            return

        if self.current_frame_index >= len(self.playback_frames):
            self.stop_playback()
            return

        # æ˜¾ç¤ºå½“å‰å¸§
        frame = self.playback_frames[self.current_frame_index]
        self.display_frame(frame)

        # æ›´æ–°è¿›åº¦
        self.progress_slider.setValue(self.current_frame_index)

        # æ›´æ–°æ—¶é—´æ˜¾ç¤º
        current_time = self.current_frame_index / self.playback_fps
        total_time = len(self.playback_frames) / self.playback_fps
        self.time_label.setText(f"{current_time:.1f}s / {total_time:.1f}s")

        self.current_frame_index += 1

    def on_progress_changed(self, value):
        """è¿›åº¦æ¡æ”¹å˜"""
        if hasattr(self, 'playback_frames') and self.playback_frames and not self.is_playing:
            self.current_frame_index = value
            frame = self.playback_frames[value]
            self.display_frame(frame)

            # æ›´æ–°æ—¶é—´æ˜¾ç¤º
            current_time = value / self.playback_fps
            total_time = len(self.playback_frames) / self.playback_fps
            self.time_label.setText(f"{current_time:.1f}s / {total_time:.1f}s")

    def display_frame(self, frame):
        """æ˜¾ç¤ºå¸§"""
        if frame is None:
            return

        # è½¬æ¢é¢œè‰²ç©ºé—´
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = frame_rgb.shape
        bytes_per_line = ch * w
        q_image = QImage(frame_rgb.data, w, h, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        # ç¼©æ”¾é€‚åº”æ˜¾ç¤ºåŒºåŸŸ
        scaled_pixmap = pixmap.scaled(
            self.video_label.size(),
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )
        self.video_label.setPixmap(scaled_pixmap)

    def delete_selected_snapshot(self):
        """åˆ é™¤é€‰ä¸­çš„å¿«ç…§"""
        if not self.snapshots or self.current_snapshot_index >= len(self.snapshots):
            return

        snapshot = self.snapshots[self.current_snapshot_index]

        reply = QMessageBox.question(
            self, "ç¡®è®¤åˆ é™¤",
            f"ç¡®å®šè¦åˆ é™¤æ‘„åƒå¤´ '{snapshot['camera_name']}' çš„å¿«ç…§å—ï¼Ÿ\næ­¤æ“ä½œä¸å¯æ¢å¤ã€‚",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )

        if reply == QMessageBox.Yes:
            try:
                # åˆ é™¤MP4å’ŒJSONæ–‡ä»¶
                Path(snapshot['mp4_path']).unlink()
                Path(snapshot['json_path']).unlink()

                # ä»åˆ—è¡¨ä¸­ç§»é™¤
                self.snapshots.pop(self.current_snapshot_index)
                self.update_snapshot_list()

                # æ¸…ç©ºæ’­æ”¾åŒºåŸŸ
                self.video_label.clear()
                self.video_label.setText("é€‰æ‹©å¿«ç…§è¿›è¡Œæ’­æ”¾")
                self.info_text.clear()

                # ç¦ç”¨æŒ‰é’®
                self.play_btn.setEnabled(False)
                self.delete_btn.setEnabled(False)
                self.export_btn.setEnabled(False)

                QMessageBox.information(self, "æˆåŠŸ", "å¿«ç…§å·²åˆ é™¤")

            except Exception as e:
                QMessageBox.critical(self, "é”™è¯¯", f"åˆ é™¤å¿«ç…§å¤±è´¥: {str(e)}")

    # æ·»åŠ å¯¼å‡ºåŠŸèƒ½çš„å®ç°
    def export_selected_snapshot(self):
        """å¯¼å‡ºé€‰ä¸­çš„å¿«ç…§"""
        if not self.snapshots or self.current_snapshot_index >= len(self.snapshots):
            return

        snapshot = self.snapshots[self.current_snapshot_index]

        # é€‰æ‹©å¯¼å‡ºç›®å½•
        export_dir = QFileDialog.getExistingDirectory(self, "é€‰æ‹©å¯¼å‡ºç›®å½•")
        if not export_dir:
            return

        try:
            export_path = Path(export_dir)
            mp4_file = Path(snapshot['mp4_path'])
            json_file = Path(snapshot['json_path'])

            # æ„é€ å¯¼å‡ºæ–‡ä»¶è·¯å¾„
            mp4_export_path = export_path / mp4_file.name
            json_export_path = export_path / json_file.name

            # å¤åˆ¶æ–‡ä»¶
            import shutil
            shutil.copy2(mp4_file, mp4_export_path)
            shutil.copy2(json_file, json_export_path)

            QMessageBox.information(self, "æˆåŠŸ", f"å¿«ç…§å·²å¯¼å‡ºåˆ°:\n{export_path}")

        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"å¯¼å‡ºå¿«ç…§å¤±è´¥: {str(e)}")


class EnhancedDetectionUI(QMainWindow):
    """å¢å¼ºçš„æ£€æµ‹UIä¸»çª—å£"""

    def __init__(self):
        super().__init__()
        self.model = None
        self.detection_thread = None
        self.batch_detection_thread = None
        self.current_source_type = 'image'
        self.current_source_path = None
        self.confidence_threshold = 0.25
        self.batch_results = []
        self.current_batch_index = 0

        # å¿«ç…§ç›¸å…³å±æ€§
        self.is_auto_saving = False
        self.video_recorder = None
        self.history_dir = Path("detection_history")
        self.history_dir.mkdir(exist_ok=True)

        # ç®¡ç†å™¨
        self.camera_manager = CameraManager()
        self.model_manager = ModelManager()
        self.log_text = QTextEdit()
        self.init_ui()
        self.setWindowIcon(self.create_enhanced_icon())

        # åº”ç”¨æ ·å¼
        self.setStyleSheet(StyleManager.get_main_stylesheet())
        self.setup_title_shortcut()

        self.slice_update_timer = QTimer()
        self.slice_update_timer.setSingleShot(True)
        self.slice_update_timer.timeout.connect(self.update_slice_preview)
        self.slice_range_changed = False

    def init_ui(self):
        """åˆå§‹åŒ–UI"""
        self.setWindowTitle("ğŸš€ åŸºäºYOLOçš„è„‘éƒ¨è‚¿ç˜¤æ£€æµ‹ç³»ç»Ÿ ")
        self.setGeometry(100, 100, 1400, 750)

        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)

        # åˆ›å»ºä¸»åˆ†å‰²å™¨
        main_splitter = QSplitter(Qt.Horizontal)

        # å·¦ä¾§æ§åˆ¶é¢æ¿
        left_widget = self.create_control_panel()
        left_widget.setMaximumWidth(500)
        left_widget.setMinimumWidth(400)

        # å³ä¾§æ˜¾ç¤ºåŒºåŸŸ
        right_widget = self.create_display_area()

        main_splitter.addWidget(left_widget)
        main_splitter.addWidget(right_widget)
        main_splitter.setSizes([450, 1250])

        main_layout.addWidget(main_splitter)

        # çŠ¶æ€æ 
        self.statusBar().showMessage("ğŸ¯ å°±ç»ª - è¯·é€‰æ‹©æ¨¡å‹å’Œæ£€æµ‹æº")

        # å°è¯•åŠ è½½é»˜è®¤æ¨¡å‹
        self.try_load_default_model()

    def setup_title_shortcut(self):
        """è®¾ç½®æ ‡é¢˜ç¼–è¾‘å¿«æ·é”®"""
        title_shortcut = QShortcut(QKeySequence("F2"), self)
        title_shortcut.activated.connect(self.edit_window_title)
        # æ·»åŠ æ–°çš„ Ctrl+R å¿«æ·é”®
        title_shortcut_ctrl_r = QShortcut(QKeySequence("Ctrl+R"), self)
        title_shortcut_ctrl_r.activated.connect(self.edit_window_title)

    def edit_window_title(self):
        """ç¼–è¾‘çª—å£æ ‡é¢˜"""
        current_title = self.windowTitle().strip()
        new_title, ok = QInputDialog.getText(
            self,
            "ç¼–è¾‘çª—å£æ ‡é¢˜",
            "è¯·è¾“å…¥æ–°çš„çª—å£æ ‡é¢˜:",
            text=current_title
        )

        if ok and new_title:
            self.setWindowTitle(new_title)

    def create_control_panel(self):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # æ¨¡å‹é…ç½®
        model_group = QGroupBox("ğŸ¤– æ¨¡å‹é…ç½®")
        model_layout = QVBoxLayout(model_group)

        # æ¨¡å‹é€‰æ‹©
        model_select_layout = QHBoxLayout()
        model_select_layout.addWidget(QLabel("é€‰æ‹©æ¨¡å‹:"))

        self.model_combo = QComboBox()
        self.model_combo.currentTextChanged.connect(self.on_model_changed)
        self.init_model_combo()
        model_select_layout.addWidget(self.model_combo)

        advanced_model_btn = QPushButton("ğŸ”§ é«˜çº§")
        advanced_model_btn.clicked.connect(self.show_model_selection_dialog)
        advanced_model_btn.setMaximumWidth(80)
        model_select_layout.addWidget(advanced_model_btn)

        model_layout.addLayout(model_select_layout)

        # ç½®ä¿¡åº¦é…ç½®
        conf_layout = QHBoxLayout()
        conf_layout.addWidget(QLabel("ç½®ä¿¡åº¦é˜ˆå€¼:"))

        self.conf_slider = QSlider(Qt.Horizontal)
        self.conf_slider.setMinimum(1)
        self.conf_slider.setMaximum(100)
        self.conf_slider.setValue(25)
        self.conf_slider.valueChanged.connect(self.on_confidence_changed)
        conf_layout.addWidget(self.conf_slider)

        self.conf_spinbox = QDoubleSpinBox()
        self.conf_spinbox.setRange(0.01, 1.0)
        self.conf_spinbox.setSingleStep(0.01)
        self.conf_spinbox.setValue(0.25)
        self.conf_spinbox.setDecimals(2)
        self.conf_spinbox.valueChanged.connect(self.on_confidence_spinbox_changed)
        conf_layout.addWidget(self.conf_spinbox)

        model_layout.addLayout(conf_layout)
        layout.addWidget(model_group)

        # æ£€æµ‹æºé…ç½®
        source_group = QGroupBox("ğŸ“ æ£€æµ‹æºé…ç½®")
        source_layout = QVBoxLayout(source_group)

        # æ£€æµ‹æ¨¡å¼é€‰æ‹©
        mode_layout = QHBoxLayout()
        mode_layout.addWidget(QLabel("æ£€æµ‹æ¨¡å¼:"))

        self.source_combo = QComboBox()
        self.source_combo.addItems(["ğŸ“· å•å¼ å›¾ç‰‡", "ğŸ¬ è§†é¢‘æ–‡ä»¶", "ğŸ“¹ æ‘„åƒå¤´", "ğŸ“‚ æ–‡ä»¶å¤¹æ‰¹é‡"])
        self.source_combo.currentTextChanged.connect(self.on_source_changed)
        mode_layout.addWidget(self.source_combo)
        source_layout.addLayout(mode_layout)

        # æ‘„åƒå¤´é€‰æ‹©ï¼ˆä»…æ‘„åƒå¤´æ¨¡å¼æ˜¾ç¤ºï¼‰
        self.camera_select_layout = QHBoxLayout()
        self.camera_select_layout.addWidget(QLabel("æ‘„åƒå¤´:"))

        self.camera_combo = QComboBox()
        self.refresh_camera_list()
        self.camera_select_layout.addWidget(self.camera_combo)

        refresh_camera_btn = QPushButton("ğŸ”„")
        refresh_camera_btn.setMaximumWidth(40)
        refresh_camera_btn.clicked.connect(self.refresh_camera_list)
        self.camera_select_layout.addWidget(refresh_camera_btn)

        source_layout.addLayout(self.camera_select_layout)

        # æ–‡ä»¶é€‰æ‹©
        file_layout = QHBoxLayout()
        self.select_file_btn = QPushButton("ğŸ“ é€‰æ‹©æ–‡ä»¶/æ–‡ä»¶å¤¹")
        self.select_file_btn.clicked.connect(self.select_file)
        file_layout.addWidget(self.select_file_btn)
        source_layout.addLayout(file_layout)

        # å½“å‰æ–‡ä»¶æ˜¾ç¤º
        self.current_file_label = QLabel("æœªé€‰æ‹©æ–‡ä»¶")
        self.current_file_label.setWordWrap(True)
        self.current_file_label.setStyleSheet("color: #7f8c8d; font-size: 11px; padding: 5px;")
        source_layout.addWidget(self.current_file_label)

        layout.addWidget(source_group)

        # æ£€æµ‹æ§åˆ¶
        control_group = QGroupBox("ğŸ® æ£€æµ‹æ§åˆ¶")
        control_layout = QVBoxLayout(control_group)

        # æ§åˆ¶æŒ‰é’®
        btn_layout = QHBoxLayout()

        self.start_btn = QPushButton("â–¶ï¸ å¼€å§‹æ£€æµ‹")
        self.start_btn.clicked.connect(self.start_detection)
        self.start_btn.setEnabled(False)
        btn_layout.addWidget(self.start_btn)

        self.pause_btn = QPushButton("â¸ï¸ æš‚åœ")
        self.pause_btn.clicked.connect(self.pause_detection)
        self.pause_btn.setEnabled(False)
        btn_layout.addWidget(self.pause_btn)

        self.stop_btn = QPushButton("â¹ï¸ åœæ­¢")
        self.stop_btn.clicked.connect(self.stop_detection)
        self.stop_btn.setEnabled(False)
        btn_layout.addWidget(self.stop_btn)
        self.video_is_auto_saving = False
        self.kuaizhao_btn = QPushButton("ğŸ¬ å¿«ç…§")
        self.kuaizhao_btn.clicked.connect(self.kuaizhao_detection)
        self.kuaizhao_btn.setEnabled(False)
        btn_layout.addWidget(self.kuaizhao_btn)

        control_layout.addLayout(btn_layout)

        # è¿›åº¦æ¡
        progress_layout = QHBoxLayout()
        progress_layout.addWidget(QLabel("è¿›åº¦:"))

        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        progress_layout.addWidget(self.progress_bar)

        control_layout.addLayout(progress_layout)

        layout.addWidget(control_group)

        # æ£€æµ‹ç»“æœè¯¦æƒ…
        # self.result_detail_widget = DetectionResultWidget()
        # layout.addWidget(self.result_detail_widget)

        # æ—¥å¿—åŒºåŸŸ
        log_group = QGroupBox("ğŸ“‹ è¿è¡Œæ—¥å¿—")
        log_layout = QVBoxLayout(log_group)

        self.log_text.setMinimumHeight(180)
        self.log_text.setFont(QFont("Consolas", 10))
        log_layout.addWidget(self.log_text)

        log_btn_layout = QHBoxLayout()
        log_btn_layout.addStretch()

        self.clear_log_btn = QPushButton("ğŸ—‘ï¸ æ¸…é™¤")
        self.clear_log_btn.clicked.connect(self.clear_log)
        self.clear_log_btn.setMaximumWidth(100)
        log_btn_layout.addWidget(self.clear_log_btn)

        log_layout.addLayout(log_btn_layout)
        layout.addWidget(log_group)

        # layout.addStretch()
        return widget

    def create_display_area(self):
        """åˆ›å»ºæ˜¾ç¤ºåŒºåŸŸ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # åˆ›å»ºæ ‡ç­¾é¡µ
        self.tab_widget = QTabWidget()

        # åˆ›å»º NIfTI æ ¼å¼è½¬æ¢æ ‡ç­¾é¡µ
        nifti_tab = self.create_nifti_conversion_tab()
        self.tab_widget.addTab(nifti_tab, " NIfTI è½¬æ¢")

        # å®æ—¶æ£€æµ‹æ ‡ç­¾é¡µ
        realtime_tab = self.create_realtime_tab()
        self.tab_widget.addTab(realtime_tab, "ğŸ¯ å®æ—¶æ£€æµ‹")

        # æ‰¹é‡ç»“æœæ ‡ç­¾é¡µ
        batch_tab = self.create_batch_tab()
        self.tab_widget.addTab(batch_tab, "ğŸ“Š æ‰¹é‡ç»“æœ")

        # ç›‘æ§é¡µé¢æ ‡ç­¾é¡µ
        monitor_tab = MonitoringWidget(self.model_manager, self.camera_manager)
        self.tab_widget.addTab(monitor_tab, "ğŸ–¥ï¸ å®æ—¶ç›‘æ§")

        # ç›‘æ§å¿«ç…§æ ‡ç­¾é¡µ
        self.snapshot_widget = SnapshotWidget()
        self.tab_widget.addTab(self.snapshot_widget, "ğŸ¬ ç›‘æ§å¿«ç…§")

        layout.addWidget(self.tab_widget)
        return widget

    def create_nifti_conversion_tab(self):
        """åˆ›å»ºNIfTIæ ¼å¼è½¬æ¢æ ‡ç­¾é¡µ"""
        nifti_tab = QWidget()
        layout = QVBoxLayout(nifti_tab)

        # æ–‡ä»¶é€‰æ‹©åŒºåŸŸ
        file_group = QGroupBox("ğŸ“ æ–‡ä»¶é€‰æ‹©")
        file_layout = QVBoxLayout(file_group)

        file_select_layout = QHBoxLayout()
        self.nii_file_edit = QLineEdit()
        self.nii_file_edit.setPlaceholderText("é€‰æ‹©NIfTIæ–‡ä»¶æˆ–ç›®å½•...")
        file_select_layout.addWidget(self.nii_file_edit)

        self.browse_nii_btn = QPushButton("æµè§ˆ")
        self.browse_nii_btn.clicked.connect(self.browse_nii_file)
        file_select_layout.addWidget(self.browse_nii_btn)

        file_layout.addLayout(file_select_layout)

        # è¾“å‡ºç›®å½•è®¾ç½®
        output_layout = QHBoxLayout()
        output_layout.addWidget(QLabel("ğŸ“¤ è¾“å‡ºç›®å½•:"))
        self.output_dir_edit = QLineEdit()
        self.output_dir_edit.setPlaceholderText("è‡ªåŠ¨è®¾ç½®ä¸ºè¾“å…¥ç›®å½• + '_swift_normal'")
        output_layout.addWidget(self.output_dir_edit)

        self.browse_output_btn = QPushButton("æµè§ˆ")
        self.browse_output_btn.clicked.connect(self.browse_output_dir)
        output_layout.addWidget(self.browse_output_btn)

        file_layout.addLayout(output_layout)

        layout.addWidget(file_group)

        # åˆ‡ç‰‡è®¾ç½®å’Œæ–‡ä»¶ä¿¡æ¯æ¨ªå‘å¸ƒå±€åŒºåŸŸ
        settings_layout = QHBoxLayout()
        # åˆ‡ç‰‡è®¾ç½®åŒºåŸŸ
        slice_group = QGroupBox("ğŸ”ª åˆ‡ç‰‡è®¾ç½®")
        slice_layout = QVBoxLayout(slice_group)

        # åˆ‡ç‰‡æ–¹å‘é€‰æ‹©
        direction_layout = QHBoxLayout()
        direction_layout.addWidget(QLabel("ğŸ§­ åˆ‡ç‰‡æ–¹å‘:"))
        self.slice_direction_combo = QComboBox()
        self.slice_direction_combo.addItems(["å† çŠ¶ä½ (Coronal)","æ°´å¹³ä½ (Axial)", "çŸ¢çŠ¶ä½ (Sagittal)"])
        self.slice_direction_combo.setCurrentText("æ°´å¹³ä½ (Axial)")
        self.slice_direction_combo.currentTextChanged.connect(self.update_slice_info)
        direction_layout.addWidget(self.slice_direction_combo)
        direction_layout.addStretch()

        slice_layout.addLayout(direction_layout)

        # åˆ‡ç‰‡èŒƒå›´è®¾ç½®
        range_layout = QHBoxLayout()
        # åœ¨åˆ›å»ºåˆ‡ç‰‡èŒƒå›´è®¾ç½®çš„éƒ¨åˆ†ï¼Œä¸º QSpinBox æ·»åŠ ä¿¡å·è¿æ¥
        range_layout.addWidget(QLabel("ğŸ“ åˆ‡ç‰‡èŒƒå›´:"))
        self.start_slice_spin = QSpinBox()
        self.start_slice_spin.setMinimum(0)
        self.start_slice_spin.setValue(60)
        self.start_slice_spin.valueChanged.connect(self.on_slice_range_changed)  # æ·»åŠ è¿™ä¸€è¡Œ
        range_layout.addWidget(self.start_slice_spin)

        range_layout.addWidget(QLabel(" - "))

        self.end_slice_spin = QSpinBox()
        self.end_slice_spin.setMinimum(0)
        self.end_slice_spin.setMaximum(1000)
        self.end_slice_spin.setValue(150)
        self.end_slice_spin.valueChanged.connect(self.on_slice_range_changed)  # æ·»åŠ è¿™ä¸€è¡Œ
        range_layout.addWidget(self.end_slice_spin)

        range_layout.addStretch()
        slice_layout.addLayout(range_layout)

        # åˆ‡ç‰‡ä¿¡æ¯æ˜¾ç¤º
        info_layout = QHBoxLayout()
        self.slice_info_label = QLabel("_slices: 0, å½“å‰èŒƒå›´: 0-0")
        info_layout.addWidget(self.slice_info_label)
        info_layout.addStretch()
        slice_layout.addLayout(info_layout)

        # layout.addWidget(slice_group)

        # æ–‡ä»¶ä¿¡æ¯æ˜¾ç¤ºåŒºåŸŸ
        info_group = QGroupBox("ğŸ“Š æ–‡ä»¶ä¿¡æ¯")
        info_layout = QVBoxLayout(info_group)

        self.file_info_text = QTextEdit()
        self.file_info_text.setReadOnly(True)
        self.file_info_text.setMaximumHeight(100)
        info_layout.addWidget(self.file_info_text)

        # layout.addWidget(info_group)
        # æ·»åŠ ä¸¤ä¸ªåŒºåŸŸåˆ°æ°´å¹³å¸ƒå±€
        settings_layout.addWidget(slice_group)
        settings_layout.addWidget(info_group)
        slice_group.setMaximumHeight(150)  # é™åˆ¶åˆ‡ç‰‡è®¾ç½®åŒºåŸŸé«˜åº¦
        info_group.setMaximumHeight(150)  # é™åˆ¶æ–‡ä»¶ä¿¡æ¯åŒºåŸŸé«˜åº¦
        # è®¾ç½®ä¸¤ä¸ªåŒºåŸŸç­‰å®½
        settings_layout.setStretch(0, 1)
        settings_layout.setStretch(1, 1)

        layout.addLayout(settings_layout)
        # é¢„è§ˆåŒºåŸŸ
        preview_group = QGroupBox("ğŸ–¼ï¸ åˆ‡ç‰‡é¢„è§ˆ")
        preview_layout = QVBoxLayout(preview_group)

        self.preview_scroll = QScrollArea()
        self.preview_scroll.setWidgetResizable(True)
        self.preview_widget = QWidget()
        self.preview_layout = QHBoxLayout(self.preview_widget)
        self.preview_scroll.setWidget(self.preview_widget)

        preview_layout.addWidget(self.preview_scroll)
        layout.addWidget(preview_group)

        # æ§åˆ¶æŒ‰é’®
        button_layout = QHBoxLayout()
        self.convert_btn = QPushButton("ğŸ”„ è½¬æ¢")
        self.convert_btn.clicked.connect(self.convert_nifti)
        self.convert_btn.setStyleSheet("QPushButton { background-color: #4CAF50; color: white; font-weight: bold; }")
        button_layout.addWidget(self.convert_btn)

        self.preview_btn = QPushButton("ğŸ‘€ é¢„è§ˆ")
        self.preview_btn.clicked.connect(self.generate_preview)
        button_layout.addWidget(self.preview_btn)

        layout.addLayout(button_layout)

        # åˆå§‹åŒ–çŠ¶æ€
        self.current_nii_file = None
        self.nii_data = None

        return nifti_tab

    def on_slice_range_changed(self, value):
        """å½“åˆ‡ç‰‡èŒƒå›´æ”¹å˜æ—¶æ›´æ–°é¢„è§ˆå›¾"""
        # è®¾ç½®æ ‡å¿—ä½ï¼Œè¡¨ç¤ºåˆ‡ç‰‡èŒƒå›´å·²æ›´æ”¹
        self.slice_range_changed = True

        # é‡å¯å®šæ—¶å™¨ï¼Œå»¶è¿Ÿæ›´æ–°é¢„è§ˆå›¾
        self.slice_update_timer.start(100)  # 300æ¯«ç§’å»¶è¿Ÿï¼Œé¿å…é¢‘ç¹æ›´æ–°
    def browse_nii_file(self):
        """æµè§ˆNIfTIæ–‡ä»¶æˆ–ç›®å½•"""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "é€‰æ‹©NIfTIæ–‡ä»¶",
            "",
            "NIfTI Files (*.nii *.nii.gz);;All Files (*)"
        )

        if file_path:
            self.nii_file_edit.setText(file_path)
            self.load_nifti_file(file_path)

    def browse_output_dir(self):
        """æµè§ˆè¾“å‡ºç›®å½•"""
        dir_path = QFileDialog.getExistingDirectory(self, "é€‰æ‹©è¾“å‡ºç›®å½•")
        if dir_path:
            self.output_dir_edit.setText(dir_path)

    def load_nifti_file(self, file_path):
        """åŠ è½½NIfTIæ–‡ä»¶å¹¶æ˜¾ç¤ºä¿¡æ¯"""
        try:
            import nibabel as nib
            self.current_nii_file = file_path
            nii = nib.load(file_path)
            self.nii_data = nii.get_fdata()

            # æ›´æ–°è¾“å‡ºç›®å½•
            if not self.output_dir_edit.text():
                input_dir = Path(file_path).parent
                output_dir = input_dir / f"{Path(file_path).stem}_swift_normal"
                self.output_dir_edit.setText(str(output_dir))

            # æ›´æ–°åˆ‡ç‰‡èŒƒå›´
            self.update_slice_range()

            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            self.display_file_info(nii)

            # ç”Ÿæˆé¢„è§ˆ
            self.generate_preview()

        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"åŠ è½½NIfTIæ–‡ä»¶å¤±è´¥: {str(e)}")

    def update_slice_range(self):
        """æ›´æ–°åˆ‡ç‰‡èŒƒå›´æ§ä»¶"""
        if self.nii_data is not None:
            # æ ¹æ®åˆ‡ç‰‡æ–¹å‘ç¡®å®šæœ€å¤§åˆ‡ç‰‡æ•°
            direction = self.slice_direction_combo.currentIndex()
            max_slices = self.nii_data.shape[direction] - 1

            self.start_slice_spin.setMaximum(max_slices)
            self.end_slice_spin.setMaximum(max_slices)
            # self.end_slice_spin.setValue(max_slices)

            self.update_slice_info()

    def update_slice_info(self):
        """æ›´æ–°åˆ‡ç‰‡ä¿¡æ¯æ˜¾ç¤º"""
        if self.nii_data is not None:
            direction = self.slice_direction_combo.currentIndex()
            max_slices = self.nii_data.shape[direction]
            start = self.start_slice_spin.value()
            end = min(self.end_slice_spin.value(), max_slices - 1)

            self.slice_info_label.setText(f"_slices: {max_slices}, å½“å‰èŒƒå›´: {start}-{end}")

    def display_file_info(self, nii):
        """æ˜¾ç¤ºNIfTIæ–‡ä»¶ä¿¡æ¯"""
        try:
            import os
            from datetime import datetime

            file_path = self.current_nii_file
            file_size = os.path.getsize(file_path)
            mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))

            header = nii.header
            shape = nii.shape
            dtype = header.get_data_dtype()
            affine = nii.affine

            # è®¡ç®—ç©ºé—´åˆ†è¾¨ç‡
            voxel_sizes = header.get_zooms()

            info_text = f"æ–‡ä»¶å¤§å°: {self.format_file_size(file_size)}\n"
            info_text += f"ä¿®æ”¹æ—¥æœŸ: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
            info_text += f"å›¾åƒç»´åº¦: {shape}\n"
            info_text += f"æ•°æ®ç±»å‹: {dtype}\n"
            info_text += f"ç©ºé—´åˆ†è¾¨ç‡: {voxel_sizes[:3] if len(voxel_sizes) >= 3 else voxel_sizes}\n"

            self.file_info_text.setText(info_text)
        except Exception as e:
            self.file_info_text.setText(f"æ— æ³•è¯»å–æ–‡ä»¶ä¿¡æ¯: {str(e)}")

    def format_file_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        if size_bytes == 0:
            return "0 B"

        size_names = ["B", "KB", "MB", "GB"]
        i = 0
        while size_bytes >= 1024 and i < len(size_names) - 1:
            size_bytes /= 1024.0
            i += 1

        return f"{size_bytes:.1f} {size_names[i]}"

    def generate_preview(self):
        """ç”Ÿæˆé¢„è§ˆå›¾åƒ"""
        if self.nii_data is None:
            return

        # æ¸…é™¤ç°æœ‰é¢„è§ˆ
        for i in reversed(range(self.preview_layout.count())):
            widget = self.preview_layout.itemAt(i).widget()
            if widget:
                widget.setParent(None)

        try:
            import matplotlib.pyplot as plt
            from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
            import numpy as np

            direction = self.slice_direction_combo.currentIndex()
            max_slices = self.nii_data.shape[direction]
            start = self.start_slice_spin.value()
            end = min(self.end_slice_spin.value(), max_slices - 1)

            # é€‰æ‹©5ä¸ªä»£è¡¨æ€§åˆ‡ç‰‡
            indices = np.linspace(start, end, 5, dtype=int)

            for idx in indices:
                # æå–åˆ‡ç‰‡
                if direction == 0:  # Sagittal
                    slice_data = self.nii_data[idx, :, :]
                elif direction == 1:  # Coronal
                    slice_data = self.nii_data[:, idx, :]
                else:  # Axial
                    slice_data = self.nii_data[:, :, idx]

                # åˆ›å»ºå›¾åƒ
                fig = plt.Figure(figsize=(2, 2), dpi=100)
                ax = fig.add_subplot(111)
                ax.imshow(slice_data, cmap='gray')
                ax.set_title(f"Slice {idx}")
                ax.axis('off')

                canvas = FigureCanvas(fig)
                canvas.setToolTip(f"åˆ‡ç‰‡ç´¢å¼•: {idx}")

                # æ·»åŠ å³é”®èœå•åŠŸèƒ½
                canvas.setContextMenuPolicy(Qt.CustomContextMenu)
                canvas.customContextMenuRequested.connect(
                    lambda pos, c=canvas, index=idx, dir_=direction:
                    self.show_slice_context_menu(pos, c, index, dir_)
                )
                self.preview_layout.addWidget(canvas)

            plt.close('all')

        except Exception as e:
            error_label = QLabel(f"é¢„è§ˆç”Ÿæˆå¤±è´¥: {str(e)}")
            self.preview_layout.addWidget(error_label)

    def show_slice_context_menu(self, pos, canvas, slice_index, direction):
        """æ˜¾ç¤ºåˆ‡ç‰‡å³é”®èœå•"""
        context_menu = QMenu(self)

        # æ·»åŠ æ”¾å¤§æ“ä½œ
        zoom_action = QAction("ğŸ” æ”¾å¤§æŸ¥çœ‹", self)
        zoom_action.triggered.connect(
            lambda: self.show_slice_detail(slice_index, direction)
        )
        context_menu.addAction(zoom_action)

        context_menu.exec(canvas.mapToGlobal(pos))

    def show_slice_detail(self, slice_index, direction):
        """æ˜¾ç¤ºåˆ‡ç‰‡è¯¦ç»†ä¿¡æ¯å¼¹çª—"""
        dialog = SliceDetailDialog(self.nii_data, slice_index, direction, self)
        dialog.exec()

    def update_slice_preview(self):
        """æ›´æ–°åˆ‡ç‰‡é¢„è§ˆå›¾"""
        if not self.slice_range_changed:
            return
        # é‡ç½®æ ‡å¿—ä½
        self.slice_range_changed = False
        # æ›´æ–°åˆ‡ç‰‡ä¿¡æ¯æ˜¾ç¤º
        self.update_slice_info()
        # é‡æ–°ç”Ÿæˆé¢„è§ˆå›¾
        if hasattr(self, 'current_nii_file') and self.current_nii_file:
            self.generate_preview()
    def convert_nifti(self):
        """æ‰§è¡ŒNIfTIè½¬æ¢"""
        if not self.current_nii_file:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©NIfTIæ–‡ä»¶")
            return

        output_dir = self.output_dir_edit.text()
        if not output_dir:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·è®¾ç½®è¾“å‡ºç›®å½•")
            return

        try:
            import nibabel as nib
            import numpy as np
            from PIL import Image
            import os

            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)

            # åŠ è½½NIfTIæ–‡ä»¶
            nii = nib.load(self.current_nii_file)
            data = nii.get_fdata()

            direction = self.slice_direction_combo.currentIndex()
            start = self.start_slice_spin.value()
            end = min(self.end_slice_spin.value(), data.shape[direction] - 1)

            # è½¬æ¢åˆ‡ç‰‡
            progress = QProgressDialog("æ­£åœ¨è½¬æ¢...", "å–æ¶ˆ", 0, end - start + 1, self)
            progress.setWindowModality(Qt.WindowModal)
            progress.show()

            count = 0
            for i in range(start, end + 1):
                if progress.wasCanceled():
                    break

                # æå–åˆ‡ç‰‡
                if direction == 0:  # Sagittal
                    slice_data = data[i, :, :]
                elif direction == 1:  # Coronal
                    slice_data = data[:, i, :]
                else:  # Axial
                    slice_data = data[:, :, i]

                # æ ‡å‡†åŒ–åˆ°0-255
                slice_data = ((slice_data - slice_data.min()) /
                              (slice_data.max() - slice_data.min()) * 255).astype(np.uint8)

                # ä¿å­˜ä¸ºPNG
                img = Image.fromarray(slice_data)
                img.save(os.path.join(output_dir, f"slice_{i:04d}.png"))

                count += 1
                progress.setValue(count)

            progress.close()
            QMessageBox.information(self, "æˆåŠŸ", f"è½¬æ¢å®Œæˆï¼å…±ä¿å­˜ {count} å¼ åˆ‡ç‰‡åˆ°:\n{output_dir}")

        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"è½¬æ¢å¤±è´¥: {str(e)}")

    def create_realtime_tab(self):
        """åˆ›å»ºå®æ—¶æ£€æµ‹æ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout_top = QVBoxLayout(widget)
        layout = QHBoxLayout(widget)

        # åŸå›¾æ˜¾ç¤º
        original_container = QWidget()
        original_layout = QVBoxLayout(original_container)

        original_title = QLabel("ğŸ“· æº")
        original_title.setStyleSheet("font-size: 14px; font-weight: bold; color: #2c3e50; margin: 0px;")
        original_layout.addWidget(original_title)

        self.original_label = QLabel("ç­‰å¾…åŠ è½½æº...")
        self.original_label.setAlignment(Qt.AlignCenter)
        self.original_label.setMinimumSize(500, 400)
        self.original_label.setStyleSheet(StyleManager.get_image_label_style())
        original_layout.addWidget(self.original_label)

        # ç»“æœå›¾æ˜¾ç¤º
        result_container = QWidget()
        result_layout = QVBoxLayout(result_container)

        result_title = QLabel("ğŸ¯ æ£€æµ‹ç»“æœ")
        result_title.setStyleSheet("font-size: 14px; font-weight: bold; color: #2c3e50; margin: 0px;")
        result_layout.addWidget(result_title)

        self.result_label = QLabel("ç­‰å¾…æ£€æµ‹ç»“æœ...")
        self.result_label.setAlignment(Qt.AlignCenter)
        self.result_label.setMinimumSize(500, 400)
        self.result_label.setStyleSheet(StyleManager.get_image_label_style())
        result_layout.addWidget(self.result_label)

        layout.addWidget(original_container)
        layout.addWidget(result_container)
        layout_top.addLayout(layout)
        # æ£€æµ‹ç»“æœè¯¦æƒ…
        self.result_detail_widget = DetectionResultWidget()
        layout_top.addWidget(self.result_detail_widget)
        layout_top.addStretch()
        return widget

    def create_batch_tab(self):
        """åˆ›å»ºæ‰¹é‡ç»“æœæ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # æ§åˆ¶æ 
        control_bar = QHBoxLayout()
        control_bar.addWidget(QLabel("ğŸ“Š æ‰¹é‡æ£€æµ‹ç»“æœ:"))
        control_bar.addStretch()

        # å¯¼èˆªæŒ‰é’®
        self.prev_result_btn = QPushButton("â¬…ï¸ ä¸Šä¸€ä¸ª")
        self.prev_result_btn.clicked.connect(self.show_prev_result)
        self.prev_result_btn.setEnabled(False)
        control_bar.addWidget(self.prev_result_btn)

        self.result_index_label = QLabel("0/0")
        self.result_index_label.setStyleSheet("font-weight: bold; margin: 0 10px;")
        control_bar.addWidget(self.result_index_label)

        self.next_result_btn = QPushButton("ä¸‹ä¸€ä¸ª â¡ï¸")
        self.next_result_btn.clicked.connect(self.show_next_result)
        self.next_result_btn.setEnabled(False)
        control_bar.addWidget(self.next_result_btn)

        # ä¿å­˜æŒ‰é’®
        self.save_results_btn = QPushButton("ğŸ’¾ ä¿å­˜ç»“æœ")
        self.save_results_btn.clicked.connect(self.save_batch_results)
        self.save_results_btn.setEnabled(False)
        control_bar.addWidget(self.save_results_btn)

        # æ¸…ç©ºæŒ‰é’®
        self.clear_results_btn = QPushButton("ğŸ—‘ï¸ æ¸…ç©ºç»“æœ")
        self.clear_results_btn.clicked.connect(self.clear_batch_results)
        self.clear_results_btn.setEnabled(False)
        control_bar.addWidget(self.clear_results_btn)

        layout.addLayout(control_bar)

        # å›¾åƒæ˜¾ç¤º
        image_layout = QHBoxLayout()

        self.batch_original_label = QLabel("ğŸ“· æ‰¹é‡æ£€æµ‹: åŸå›¾")
        self.batch_original_label.setAlignment(Qt.AlignCenter)
        self.batch_original_label.setMinimumSize(500, 400)
        self.batch_original_label.setStyleSheet(StyleManager.get_image_label_style())

        self.batch_result_label = QLabel("ğŸ¯ æ‰¹é‡æ£€æµ‹: ç»“æœå›¾")
        self.batch_result_label.setAlignment(Qt.AlignCenter)
        self.batch_result_label.setMinimumSize(500, 400)
        self.batch_result_label.setStyleSheet(StyleManager.get_image_label_style())

        image_layout.addWidget(self.batch_original_label)
        image_layout.addWidget(self.batch_result_label)
        layout.addLayout(image_layout)

        # ç»“æœä¿¡æ¯
        self.batch_info_label = QLabel("ğŸ“ é€‰æ‹©æ–‡ä»¶å¤¹å¼€å§‹æ‰¹é‡æ£€æµ‹...")
        self.batch_info_label.setWordWrap(True)
        self.batch_info_label.setStyleSheet("""
            background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                stop:0 rgba(236, 240, 241, 0.9), stop:1 rgba(189, 195, 199, 0.9));
            padding: 15px;
            border-radius: 8px;
            font-size: 12px;
            color: #2c3e50;
        """)
        layout.addWidget(self.batch_info_label)

        return widget

    def update_time(self):
        """æ›´æ–°æ—¶é—´æ˜¾ç¤º"""
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.time_label.setText(f"ğŸ•’ {current_time}")

    def start_all_cameras(self):
        """å¯åŠ¨æ‰€æœ‰é€‰ä¸­çš„æ‘„åƒå¤´"""
        selected_cameras = [i for i, cb in enumerate(self.camera_checkboxes) if cb.isChecked()]
        for cam_idx in selected_cameras:
            self.start_camera(cam_idx)

    def pause_all_cameras(self):
        """æš‚åœæ‰€æœ‰æ‘„åƒå¤´"""
        for widget in self.video_widgets:
            if widget.isVisible():
                widget.pause_detection()

    def stop_all_cameras(self):
        """åœæ­¢æ‰€æœ‰æ‘„åƒå¤´"""
        for widget in self.video_widgets:
            if widget.isVisible():
                widget.stop_detection()

    def clear_all_cameras(self):
        """æ¸…ç©ºæ‰€æœ‰æ‘„åƒå¤´ç”»é¢"""
        for widget in self.video_widgets:
            if widget.isVisible():
                widget.clear_frame()

    def monitor_all_cameras(self):
        """å°†æ‰€æœ‰æ‘„åƒå¤´åˆ‡æ¢ä¸ºç›‘æ§æ¨¡å¼"""
        for widget in self.video_widgets:
            if widget.isVisible():
                widget.set_monitor_mode(True)

    def start_camera(self, camera_index):
        """å¯åŠ¨æŒ‡å®šæ‘„åƒå¤´"""
        if 0 <= camera_index < len(self.video_widgets):
            widget = self.video_widgets[camera_index]
            widget.show()
            widget.start_detection(camera_index + 1)  # å‡è®¾æ‘„åƒå¤´IDä»1å¼€å§‹

    def update_stats(self, fall_count=0, normal_count=0):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        total = fall_count + normal_count
        self.stats_label.setText(f"ğŸ“Š ä»Šæ—¥æ£€æµ‹: {total} | è·Œå€’: {fall_count} | æ­£å¸¸: {normal_count}")

    def init_model_combo(self):
        """åˆå§‹åŒ–æ¨¡å‹ä¸‹æ‹‰æ¡†"""
        self.model_combo.clear()
        models = self.model_manager.scan_models()

        if not models:
            self.model_combo.addItem("æ— å¯ç”¨æ¨¡å‹")
            self.model_combo.setEnabled(False)
        else:
            self.model_combo.addItems([model['name'] for model in models])
            self.model_combo.setEnabled(True)

    def try_load_default_model(self):
        """å°è¯•åŠ è½½é»˜è®¤æ¨¡å‹"""
        if self.model_combo.count() > 0 and self.model_combo.itemText(0) != "æ— å¯ç”¨æ¨¡å‹":
            first_model = self.model_combo.itemText(0)
            self.load_model_by_name(first_model)

    def load_model_by_name(self, model_name):
        """æ ¹æ®åç§°åŠ è½½æ¨¡å‹"""
        models = self.model_manager.scan_models()
        for model in models:
            if model['name'] == model_name:
                self.load_model(model['path'])
                break

    def load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        try:
            self.model = YOLO(model_path)
            self.log_message(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {Path(model_path).name}")
            # self.update_button_states()
            return True
        except Exception as e:
            self.log_message(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            self.model = None
            return False

    def show_model_selection_dialog(self):
        """æ˜¾ç¤ºæ¨¡å‹é€‰æ‹©å¯¹è¯æ¡†"""
        dialog = ModelSelectionDialog(self.model_manager, self)
        if dialog.exec() == QDialog.Accepted and dialog.selected_model:
            if self.load_model(dialog.selected_model):
                model_name = Path(dialog.selected_model).name
                # æ›´æ–°ä¸‹æ‹‰æ¡†
                index = self.model_combo.findText(model_name)
                if index >= 0:
                    self.model_combo.setCurrentIndex(index)
                else:
                    self.model_combo.addItem(model_name)
                    self.model_combo.setCurrentText(model_name)

    def refresh_camera_list(self):
        """åˆ·æ–°æ‘„åƒå¤´åˆ—è¡¨"""
        self.camera_manager.scan_cameras()
        self.camera_combo.clear()

        cameras = self.camera_manager.get_available_cameras()
        if cameras:
            for camera in cameras:
                self.camera_combo.addItem(f"{camera['name']} ({camera['resolution']})", camera['id'])
        else:
            self.camera_combo.addItem("æœªæ£€æµ‹åˆ°æ‘„åƒå¤´", -1)

    def on_model_changed(self, model_text):
        """æ¨¡å‹é€‰æ‹©æ”¹å˜"""
        if model_text != "æ— å¯ç”¨æ¨¡å‹":
            self.load_model_by_name(model_text)

    def on_confidence_changed(self, value):
        """ç½®ä¿¡åº¦æ»‘å—æ”¹å˜"""
        conf_value = value / 100.0
        self.confidence_threshold = conf_value
        self.conf_spinbox.blockSignals(True)
        self.conf_spinbox.setValue(conf_value)
        self.conf_spinbox.blockSignals(False)

    def on_confidence_spinbox_changed(self, value):
        """ç½®ä¿¡åº¦æ•°å€¼æ¡†æ”¹å˜"""
        self.confidence_threshold = value
        self.conf_slider.blockSignals(True)
        self.conf_slider.setValue(int(value * 100))
        self.conf_slider.blockSignals(False)

    def on_source_changed(self, source_text):
        """æ£€æµ‹æºæ”¹å˜"""
        source_map = {
            "ğŸ“· å•å¼ å›¾ç‰‡": "image",
            "ğŸ¬ è§†é¢‘æ–‡ä»¶": "video",
            "ğŸ“¹ æ‘„åƒå¤´": "camera",
            "ğŸ“‚ æ–‡ä»¶å¤¹æ‰¹é‡": "batch"
        }
        self.current_source_type = source_map.get(source_text)

        # æ˜¾ç¤º/éšè—æ‘„åƒå¤´é€‰æ‹©
        is_camera = self.current_source_type == "camera"
        for i in range(self.camera_select_layout.count()):
            item = self.camera_select_layout.itemAt(i)
            if item.widget():
                item.widget().setVisible(is_camera)

        self.current_source_path = None
        self.current_file_label.setText("æœªé€‰æ‹©æ–‡ä»¶")
        self.clear_display_windows()
        self.update_button_states()

    def update_button_states(self):
        """æ›´æ–°æŒ‰é’®çŠ¶æ€"""
        has_model = self.model is not None

        if self.current_source_type == "camera":
            has_source = self.camera_combo.currentData() != -1
            self.select_file_btn.setEnabled(False)
        else:
            has_source = self.current_source_path is not None
            self.select_file_btn.setEnabled(True)

        self.start_btn.setEnabled(has_model and has_source)

    def select_file(self):
        """é€‰æ‹©æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹"""
        if self.current_source_type == "image":
            file_path, _ = QFileDialog.getOpenFileName(
                self, "é€‰æ‹©å›¾ç‰‡", "",
                "å›¾ç‰‡æ–‡ä»¶ (*.jpg *.jpeg *.png *.bmp *.tiff *.webp);;æ‰€æœ‰æ–‡ä»¶ (*)"
            )
        elif self.current_source_type == "video":
            file_path, _ = QFileDialog.getOpenFileName(
                self, "é€‰æ‹©è§†é¢‘", "",
                "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mov *.mkv *.wmv *.flv);;æ‰€æœ‰æ–‡ä»¶ (*)"
            )
        elif self.current_source_type == "batch":
            file_path = QFileDialog.getExistingDirectory(self, "é€‰æ‹©åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹")
        else:
            return

        if file_path:
            self.current_source_path = file_path
            self.current_file_label.setText(f"ğŸ“ å·²é€‰æ‹©: {Path(file_path).name}")
            self.log_message(f"ğŸ“ å·²é€‰æ‹©: {file_path}")
            self.update_button_states()

            if self.current_source_type in ["image", "video"]:
                self.preview_file(file_path)

    def preview_file(self, file_path):
        """é¢„è§ˆæ–‡ä»¶"""
        try:
            if self.current_source_type == "image":
                img = cv2.imread(file_path)
                if img is not None:
                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    self.display_image(img_rgb, self.original_label)
                    self.result_label.clear()
                    self.result_label.setText("ç­‰å¾…æ£€æµ‹ç»“æœ...")
        except Exception as e:
            self.log_message(f"âŒ é¢„è§ˆæ–‡ä»¶å¤±è´¥: {str(e)}")

    def start_detection(self):
        """å¼€å§‹æ£€æµ‹"""
        if not self.model:
            self.log_message("âŒ é”™è¯¯: æ¨¡å‹æœªåŠ è½½")
            return

        if self.current_source_type == "batch":
            self.start_batch_detection()
        else:
            self.start_single_detection()

    def start_single_detection(self):
        """å¼€å§‹å•ä¸ªæ£€æµ‹"""
        camera_id = 0
        if self.current_source_type == "camera":
            camera_id = self.camera_combo.currentData()
            if camera_id == -1:
                self.log_message("âŒ é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„æ‘„åƒå¤´")
                return

        self.detection_thread = DetectionThread(
            self.model, self.current_source_type, self.current_source_path, camera_id, self.confidence_threshold
        )
        self.detection_thread.result_ready.connect(self.on_detection_result)
        self.detection_thread.progress_updated.connect(self.progress_bar.setValue)
        self.detection_thread.status_changed.connect(self.statusBar().showMessage)
        self.detection_thread.error_occurred.connect(self.log_message)
        self.detection_thread.finished.connect(self.on_detection_finished)

        self.update_detection_ui_state(True)
        self.tab_widget.setCurrentIndex(0)  # åˆ‡æ¢åˆ°å®æ—¶æ£€æµ‹

        self.detection_thread.start()
        self.log_message(f"ğŸš€ å¼€å§‹{self.current_source_type}æ£€æµ‹...")

    def start_batch_detection(self):
        """å¼€å§‹æ‰¹é‡æ£€æµ‹"""
        self.batch_results.clear()

        self.batch_detection_thread = BatchDetectionThread(
            self.model, self.current_source_path, self.confidence_threshold
        )
        self.batch_detection_thread.result_ready.connect(self.on_batch_result)
        self.batch_detection_thread.progress_updated.connect(self.progress_bar.setValue)
        self.batch_detection_thread.current_file_changed.connect(self.statusBar().showMessage)
        self.batch_detection_thread.finished.connect(self.on_batch_finished)

        self.update_detection_ui_state(True)
        self.tab_widget.setCurrentIndex(1)  # åˆ‡æ¢åˆ°æ‰¹é‡ç»“æœ

        self.batch_detection_thread.start()
        self.log_message("ğŸš€ å¼€å§‹æ‰¹é‡æ£€æµ‹...")

    def update_detection_ui_state(self, detecting):
        """æ›´æ–°æ£€æµ‹çŠ¶æ€çš„UI"""
        self.start_btn.setEnabled(not detecting)
        self.pause_btn.setEnabled(detecting and self.current_source_type != "batch")
        self.stop_btn.setEnabled(detecting)
        self.source_combo.setEnabled(not detecting)
        self.select_file_btn.setEnabled(not detecting and self.current_source_type != "camera")
        self.model_combo.setEnabled(not detecting)
        # æ›´æ–°å¿«ç…§æŒ‰é’®çŠ¶æ€
        self.kuaizhao_btn.setEnabled(detecting and self.current_source_type in ["camera", "video"])

    def pause_detection(self):
        """æš‚åœ/æ¢å¤æ£€æµ‹"""
        if self.detection_thread and self.detection_thread.is_running:
            if self.detection_thread.is_paused:
                self.detection_thread.resume()
                self.pause_btn.setText("â¸ï¸ æš‚åœ")
                self.log_message("â–¶ï¸ æ£€æµ‹å·²æ¢å¤")
            else:
                self.detection_thread.pause()
                self.pause_btn.setText("â–¶ï¸ ç»§ç»­")
                self.log_message("â¸ï¸ æ£€æµ‹å·²æš‚åœ")

    def stop_detection(self):
        """åœæ­¢æ£€æµ‹"""
        if self.detection_thread and self.detection_thread.is_running:
            self.detection_thread.stop()
            self.detection_thread.wait()

        if self.batch_detection_thread and self.batch_detection_thread.is_running:
            self.batch_detection_thread.stop()
            self.batch_detection_thread.wait()

        self.on_detection_finished()

    def kuaizhao_detection(self):
        """åˆ‡æ¢è‡ªåŠ¨ä¿å­˜ç›‘æ§å¿«ç…§çŠ¶æ€"""
        if not self.video_is_auto_saving:
            self.start_auto_save()
        else:
            self.stop_auto_save()

    def start_auto_save(self):
        """å¼€å§‹è‡ªåŠ¨ä¿å­˜å¿«ç…§"""
        if not self.model:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹")
            return

        # åˆå§‹åŒ–è§†é¢‘å½•åˆ¶å™¨
        source_name = "æ‘„åƒå¤´" if self.current_source_type == "camera" else "è§†é¢‘"
        if self.current_source_type == "camera":
            source_id = self.camera_combo.currentData()
            source_name = f"æ‘„åƒå¤´{source_id}"
        elif self.current_source_type == "video":
            source_name = Path(self.current_source_path).stem

        self.video_recorder = DetectionVideoRecorder(
            source_name, self.history_dir
        )
        self.video_recorder.start_recording()

        self.video_is_auto_saving = True
        self.kuaizhao_btn.setText("â¹ï¸ åœæ­¢å¿«ç…§")
        self.log_message("ğŸ¬ å¼€å§‹è®°å½•å¿«ç…§")

    def stop_auto_save(self):
        """åœæ­¢è‡ªåŠ¨ä¿å­˜å¿«ç…§"""
        if self.video_recorder:
            self.video_recorder.stop_recording()
            self.video_recorder = None

        self.video_is_auto_saving = False
        self.kuaizhao_btn.setText("ğŸ¬ å¿«ç…§")
        self.log_message("â¹ï¸ åœæ­¢è®°å½•å¿«ç…§")

    def on_detection_result(self, original_img, result_img, inference_time, results, class_names):
        """æ£€æµ‹ç»“æœå›è°ƒ"""
        # æ˜¾ç¤ºå›¾åƒ
        self.display_image(original_img, self.original_label)
        self.display_image(result_img, self.result_label)

        # æ›´æ–°ç»“æœè¯¦æƒ…
        self.result_detail_widget.update_results(results, class_names, inference_time)

        # å¦‚æœæ­£åœ¨å½•åˆ¶å¿«ç…§ï¼Œæ·»åŠ å¸§
        if self.video_is_auto_saving and self.video_recorder:
            detection_info = {
                'results': results,
                'class_names': class_names,
                'inference_time': inference_time
            }

            self.video_recorder.add_frame(result_img, detection_info)

        # è®°å½•æ—¥å¿—ï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…è¿‡å¤šè¾“å‡ºï¼‰
        if results and results[0].boxes and len(results[0].boxes) > 0:
            object_count = len(results[0].boxes)

            # ç»Ÿè®¡ç±»åˆ«
            classes = results[0].boxes.cls.cpu().numpy().astype(int)
            class_counts = {}
            for cls in classes:
                class_name = class_names[cls] if cls < len(class_names) else f"ç±»åˆ«{cls}"
                class_counts[class_name] = class_counts.get(class_name, 0) + 1

            class_summary = ", ".join([f"{name}:{count}" for name, count in class_counts.items()])
            self.log_message(f"ğŸ¯ æ£€æµ‹åˆ° {object_count} ä¸ªç›®æ ‡: {class_summary} (è€—æ—¶: {inference_time:.3f}s)")
        else:
            self.log_message(f"âšª æœªæ£€æµ‹åˆ°ç›®æ ‡ (è€—æ—¶: {inference_time:.3f}s)")

    def on_batch_result(self, file_path, original_img, result_img, inference_time, results, class_names):
        """æ‰¹é‡æ£€æµ‹ç»“æœå›è°ƒ"""
        # è®¡ç®—ç›®æ ‡æ•°é‡
        object_count = len(results[0].boxes) if results and results[0].boxes else 0

        # ä¿å­˜ç»“æœ
        result_data = {
            'file_path': file_path,
            'original_img': original_img,
            'result_img': result_img,
            'inference_time': inference_time,
            'results': results,
            'class_names': class_names,
            'object_count': object_count
        }

        self.batch_results.append(result_data)

        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»“æœ
        if len(self.batch_results) == 1:
            self.current_batch_index = 0
            self.show_batch_result(0)

        self.update_batch_navigation()

        # è®°å½•æ—¥å¿—
        filename = Path(file_path).name
        if object_count > 0:
            self.log_message(f"âœ… {filename}: {object_count} ä¸ªç›®æ ‡ ({inference_time:.3f}s)")
        else:
            self.log_message(f"âšª {filename}: æ— ç›®æ ‡ ({inference_time:.3f}s)")

    def on_batch_finished(self):
        """æ‰¹é‡æ£€æµ‹å®Œæˆ"""
        total_count = len(self.batch_results)
        total_objects = sum(result['object_count'] for result in self.batch_results)

        self.log_message(f"ğŸ‰ æ‰¹é‡æ£€æµ‹å®Œæˆ! å¤„ç†äº† {total_count} å¼ å›¾ç‰‡ï¼Œæ£€æµ‹åˆ° {total_objects} ä¸ªç›®æ ‡")
        self.statusBar().showMessage(f"æ‰¹é‡æ£€æµ‹å®Œæˆ - {total_count} å¼ å›¾ç‰‡ï¼Œ{total_objects} ä¸ªç›®æ ‡")

        self.save_results_btn.setEnabled(True)
        self.clear_results_btn.setEnabled(True)
        self.result_index_label.setText(f"1/{len(self.batch_results)}")
        self.on_detection_finished()

    def on_detection_finished(self):
        """æ£€æµ‹å®Œæˆå›è°ƒ"""
        self.update_detection_ui_state(False)
        self.pause_btn.setText("â¸ï¸ æš‚åœ")
        self.progress_bar.setValue(0)

        # åœæ­¢å¿«ç…§å½•åˆ¶
        if self.video_is_auto_saving:
            self.stop_auto_save()

    def show_batch_result(self, index):
        """æ˜¾ç¤ºæ‰¹é‡ç»“æœ"""
        if 0 <= index < len(self.batch_results):
            result = self.batch_results[index]

            self.display_image(result['original_img'], self.batch_original_label)
            self.display_image(result['result_img'], self.batch_result_label)

            filename = Path(result['file_path']).name
            object_count = result['object_count']
            inference_time = result['inference_time']

            info_text = f"ğŸ“ æ–‡ä»¶: {filename}\n"
            info_text += f"ğŸ¯ æ£€æµ‹ç›®æ ‡: {object_count} ä¸ª\n"
            info_text += f"â±ï¸ æ¨ç†è€—æ—¶: {inference_time:.3f} ç§’\n"

            if result['results'] and result['results'][0].boxes and len(result['results'][0].boxes) > 0:
                # æ˜¾ç¤ºç±»åˆ«ç»Ÿè®¡
                classes = result['results'][0].boxes.cls.cpu().numpy().astype(int)
                confidences = result['results'][0].boxes.conf.cpu().numpy()

                class_counts = {}
                for cls in classes:
                    class_name = result['class_names'][cls] if cls < len(result['class_names']) else f"ç±»åˆ«{cls}"
                    class_counts[class_name] = class_counts.get(class_name, 0) + 1

                info_text += "ğŸ“Š ç±»åˆ«ç»Ÿè®¡: " + ", ".join(
                    [f"{name}:{count}" for name, count in class_counts.items()]) + ""
                info_text += f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.3f}"

            self.batch_info_label.setText(info_text)
            self.result_index_label.setText(f"{index + 1}/{len(self.batch_results)}")

    def show_prev_result(self):
        """æ˜¾ç¤ºä¸Šä¸€ä¸ªç»“æœ"""
        if self.current_batch_index > 0:
            self.current_batch_index -= 1
            self.show_batch_result(self.current_batch_index)
            self.update_batch_navigation()

    def show_next_result(self):
        """æ˜¾ç¤ºä¸‹ä¸€ä¸ªç»“æœ"""
        if self.current_batch_index < len(self.batch_results) - 1:
            self.current_batch_index += 1
            self.show_batch_result(self.current_batch_index)
            self.update_batch_navigation()

    def update_batch_navigation(self):
        """æ›´æ–°æ‰¹é‡ç»“æœå¯¼èˆª"""
        has_results = len(self.batch_results) > 0
        self.prev_result_btn.setEnabled(has_results and self.current_batch_index > 0)
        self.next_result_btn.setEnabled(has_results and self.current_batch_index < len(self.batch_results) - 1)

    def clear_batch_results(self):
        self.batch_results.clear()
        self.batch_result_label.setText('ğŸ¯ æ‰¹é‡æ£€æµ‹: ç»“æœå›¾')
        self.batch_original_label.setText('ğŸ“· æ‰¹é‡æ£€æµ‹: åŸå›¾')
        self.batch_info_label.setText('ğŸ“ é€‰æ‹©æ–‡ä»¶å¤¹å¼€å§‹æ‰¹é‡æ£€æµ‹...')
        self.result_index_label.setText("0/0")
        self.save_results_btn.setEnabled(False)
        self.next_result_btn.setEnabled(False)
        self.prev_result_btn.setEnabled(False)
        self.clear_results_btn.setEnabled(False)

    def save_batch_results(self):
        """ä¿å­˜æ‰¹é‡æ£€æµ‹ç»“æœ"""
        if not self.batch_results:
            QMessageBox.information(self, "æç¤º", "æ²¡æœ‰å¯ä¿å­˜çš„ç»“æœ")
            return

        save_dir = QFileDialog.getExistingDirectory(self, "é€‰æ‹©ä¿å­˜ç›®å½•")
        if not save_dir:
            return

        try:
            save_path = Path(save_dir)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_dir = save_path / f"detection_results_{timestamp}"
            result_dir.mkdir(exist_ok=True)

            # ä¿å­˜æ£€æµ‹ç»“æœå›¾ç‰‡
            for i, result in enumerate(self.batch_results):
                file_name = Path(result['file_path']).stem
                result_img = cv2.cvtColor(result['result_img'], cv2.COLOR_RGB2BGR)
                result_save_path = result_dir / f"{file_name}_result.jpg"
                cv2.imwrite(str(result_save_path), result_img)

            # ä¿å­˜æ£€æµ‹æŠ¥å‘Š
            self.save_detection_report(result_dir)

            QMessageBox.information(self, "æˆåŠŸ", f"ç»“æœå·²ä¿å­˜åˆ°:\n{result_dir}")
            self.log_message(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_dir}")

        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"ä¿å­˜å¤±è´¥: {str(e)}")
            self.log_message(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")

    def save_detection_report(self, result_dir):
        """ä¿å­˜æ£€æµ‹æŠ¥å‘Š"""
        report_path = result_dir / "detection_report.txt"

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("ğŸ¯ åŸºäºYOLOçš„è„‘éƒ¨è‚¿ç˜¤æ£€æµ‹ç³»ç»Ÿ - æ‰¹é‡æ£€æµ‹æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n")
            f.write(f"ğŸ“… å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ğŸšï¸ ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}\n")
            f.write(f"ğŸ“‚ å¤„ç†å›¾ç‰‡æ•°é‡: {len(self.batch_results)}\n")
            f.write(f"ğŸ¯ æ€»æ£€æµ‹ç›®æ ‡æ•°: {sum(r['object_count'] for r in self.batch_results)}\n")
            f.write("\nğŸ“Š è¯¦ç»†ç»“æœ:\n")
            f.write("-" * 60 + "\n")

            for i, result in enumerate(self.batch_results, 1):
                f.write(f"{i}. ğŸ“ {Path(result['file_path']).name}\n")
                f.write(f"   ğŸ¯ æ£€æµ‹ç›®æ ‡: {result['object_count']} ä¸ª\n")
                f.write(f"   â±ï¸ æ¨ç†è€—æ—¶: {result['inference_time']:.3f} ç§’\n")

                if result['results'] and result['results'][0].boxes and len(result['results'][0].boxes) > 0:
                    confidences = result['results'][0].boxes.conf.cpu().numpy()
                    classes = result['results'][0].boxes.cls.cpu().numpy().astype(int)

                    f.write(f"   ğŸ“ˆ ç½®ä¿¡åº¦èŒƒå›´: {np.min(confidences):.3f} - {np.max(confidences):.3f}\n")

                    # ç±»åˆ«ç»Ÿè®¡
                    class_counts = {}
                    for cls in classes:
                        class_name = result['class_names'][cls] if cls < len(result['class_names']) else f"ç±»åˆ«{cls}"
                        class_counts[class_name] = class_counts.get(class_name, 0) + 1

                    f.write("   ğŸ“Š ç±»åˆ«åˆ†å¸ƒ: " + ", ".join(
                        [f"{name}:{count}" for name, count in class_counts.items()]) + "\n")

                f.write("\n")

    def clear_display_windows(self):
        """æ¸…ç©ºæ˜¾ç¤ºçª—å£"""
        self.original_label.clear()
        self.original_label.setText("ç­‰å¾…åŠ è½½æº...")
        self.result_label.clear()
        self.result_label.setText("ç­‰å¾…æ£€æµ‹ç»“æœ...")

    def display_image(self, img_array, label):
        """æ˜¾ç¤ºå›¾åƒ"""
        if img_array is None:
            return

        height, width, channel = img_array.shape
        bytes_per_line = 3 * width
        q_image = QImage(img_array.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
        label.setPixmap(scaled_pixmap)

    def clear_display(self, lable):
        pass

    def log_message(self, message):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_text.append(f"[{timestamp}] {message}")

        # é™åˆ¶æ—¥å¿—è¡Œæ•°
        max_lines = 1000
        lines = self.log_text.toPlainText().split('\n')
        if len(lines) > max_lines:
            keep_lines = lines[-500:]
            self.log_text.setPlainText('\n'.join(keep_lines))

        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        scrollbar = self.log_text.verticalScrollBar()
        scrollbar.setValue(scrollbar.maximum())

    def clear_log(self):
        """æ¸…é™¤æ—¥å¿—"""
        self.log_text.clear()
        self.log_message("ğŸ—‘ï¸ æ—¥å¿—å·²æ¸…é™¤")

    def create_enhanced_icon(self, size=64):
        """åˆ›å»ºå¢å¼ºçš„åº”ç”¨å›¾æ ‡"""
        icon = QIcon()

        for s in [16, 32, 48, 64, 128, 256]:
            pixmap = QPixmap(s, s)
            pixmap.fill(Qt.transparent)

            painter = QPainter(pixmap)
            painter.setRenderHint(QPainter.Antialiasing)

            # æ¸å˜èƒŒæ™¯
            gradient = QRadialGradient(s / 2, s / 2, s / 2)
            gradient.setColorAt(0, QColor("#3498db"))
            gradient.setColorAt(1, QColor("#2c3e50"))

            painter.setBrush(QBrush(gradient))
            painter.setPen(Qt.NoPen)
            painter.drawEllipse(0, 0, s, s)

            # åå­—å‡†æ˜Ÿ
            painter.setPen(QPen(QColor("white"), max(1, s // 32), Qt.SolidLine))
            center = s / 2
            arm_len = s * 0.25

            painter.drawLine(center - arm_len, center, center + arm_len, center)
            painter.drawLine(center, center - arm_len, center, center + arm_len)

            # ä¸­å¿ƒåœ†ç‚¹
            painter.setBrush(QBrush(QColor("white")))
            r = max(2, s // 16)
            painter.drawEllipse(center - r, center - r, 2 * r, 2 * r)

            # AI çœ¼ç›æ•ˆæœ
            painter.setPen(QPen(QColor("#e74c3c"), max(1, s // 64), Qt.SolidLine))
            painter.setBrush(Qt.NoBrush)

            # å¤–åœˆ
            outer_r = s * 0.35
            painter.drawEllipse(center - outer_r, center - outer_r, 2 * outer_r, 2 * outer_r)

            painter.end()
            icon.addPixmap(pixmap)

        return icon


class DetectionVideoRecorder:
    """æ£€æµ‹è§†é¢‘å½•åˆ¶å™¨ï¼Œç”¨äºè®°å½•å®æ—¶æ£€æµ‹çš„å¿«ç…§"""

    def __init__(self, source_name, output_dir, fps=20):
        self.source_name = source_name
        self.output_dir = output_dir
        self.fps = fps
        self.is_recording = False
        self.video_writer = None
        self.frames = []
        self.detection_stats = {}
        self.total_detections = 0
        self.start_time = None
        self.end_time = None
        self.max_frames_per_file = fps * 60 * 60 * 24  # 24å°æ—¶çš„è§†é¢‘

    def start_recording(self):
        """å¼€å§‹å½•åˆ¶"""
        if self.is_recording:
            return

        self.is_recording = True
        self.start_time = time.time()
        self.frames.clear()
        self.detection_stats.clear()
        self.total_detections = 0

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = int(self.start_time)
        self.filename_base = f"{self.source_name}_{timestamp}"
        self.mp4_path = self.output_dir / f"{self.filename_base}.mp4"
        self.json_path = self.output_dir / f"{self.filename_base}.json"

        # åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨ï¼ˆç¨ååœ¨æ·»åŠ ç¬¬ä¸€å¸§æ—¶è®¾ç½®ï¼‰
        self.video_writer = None

    def add_frame(self, frame, detection_info):
        """æ·»åŠ å¸§"""
        if not self.is_recording:
            return
        # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹ç»“æœ
        if not detection_info or not detection_info.get('results'):
            return

        results = detection_info['results']
        if not hasattr(results[0], 'boxes') or not results[0].boxes or len(results[0].boxes) == 0:
            return
        # å¦‚æœæ˜¯ç¬¬ä¸€å¸§ï¼Œåˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨
        if self.video_writer is None:
            height, width = frame.shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            self.video_writer = cv2.VideoWriter(str(self.mp4_path), fourcc, self.fps, (width, height))

        # å†™å…¥å¸§ - è§£å†³è‰²å·®é—®é¢˜ï¼šå°†RGBè½¬æ¢ä¸ºBGR
        if frame.shape[2] == 3:  # ç¡®ä¿æ˜¯3é€šé“å½©è‰²å›¾åƒ
            bgr_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            self.video_writer.write(bgr_frame)
        else:
            self.video_writer.write(frame)

        self.frames.append(frame.copy())

        # æ›´æ–°æ£€æµ‹ç»Ÿè®¡
        if detection_info and detection_info.get('results'):
            results = detection_info['results']
            if hasattr(results[0], 'boxes') and results[0].boxes and len(results[0].boxes) > 0:
                self.total_detections += len(results[0].boxes)

                # ç»Ÿè®¡ç±»åˆ«
                if hasattr(results[0].boxes, 'cls'):
                    classes = results[0].boxes.cls.cpu().numpy().astype(int)
                    class_names = detection_info.get('class_names', [])

                    for cls in classes:
                        if cls < len(class_names):
                            class_name = class_names[cls]
                            self.detection_stats[class_name] = self.detection_stats.get(class_name, 0) + 1

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ–‡ä»¶
        if len(self.frames) >= self.max_frames_per_file:
            self.save_recording()
            self.start_recording()  # å¼€å§‹æ–°çš„å½•åˆ¶

    def stop_recording(self):
        """åœæ­¢å½•åˆ¶"""
        if not self.is_recording:
            return

        self.is_recording = False
        self.end_time = time.time()

        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None

        # ä¿å­˜å½•åˆ¶
        if self.frames:
            self.save_recording()

    def save_recording(self):
        """ä¿å­˜å½•åˆ¶"""
        if not self.frames or not self.start_time:
            return

        # ç¡®ä¿è§†é¢‘å†™å…¥å™¨å·²é‡Šæ”¾
        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None

        # ä¿å­˜JSONå…ƒæ•°æ®
        metadata = {
            'camera_id': self.source_name,
            'source_name': self.source_name,
            'start_time': self.start_time,
            'end_time': self.end_time or time.time(),
            'fps': self.fps,
            'total_detections': self.total_detections,
            'detection_stats': self.detection_stats,
            'frame_count': len(self.frames),
            'mp4_filename': self.mp4_path.name,
            'json_filename': self.json_path.name
        }

        with open(self.json_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"ä¿å­˜æ£€æµ‹å¿«ç…§: {self.source_name} - {len(self.frames)} å¸§, {self.total_detections} æ¬¡æ£€æµ‹")
        print(f"æ–‡ä»¶è·¯å¾„: {self.mp4_path}")
        print(f"JSONè·¯å¾„: {self.json_path}")


def main():
    app = QApplication(sys.argv)

    # è®¾ç½®åº”ç”¨ç¨‹åºä¿¡æ¯
    app.setApplicationName("åŸºäºYOLOçš„è„‘éƒ¨è‚¿ç˜¤æ£€æµ‹ç³»ç»Ÿ")
    app.setApplicationVersion("2.0")
    app.setOrganizationName("AI Vision Lab")

    # è®¾ç½®é«˜DPIç¼©æ”¾
    # app.setAttribute(Qt.AA_EnableHighDpiScaling)
    # app.setAttribute(Qt.AA_UseHighDpiPixmaps)

    # åˆ›å»ºä¸»çª—å£
    window = EnhancedDetectionUI()
    window.show()

    # å¯åŠ¨æ¶ˆæ¯
    window.log_message("ğŸš€ åŸºäºYOLOçš„è„‘éƒ¨è‚¿ç˜¤æ£€æµ‹ç³»ç»Ÿ å·²å¯åŠ¨")
    window.log_message("âœ¨ æ–°åŠŸèƒ½: æ¸å˜UIã€å¤šæ‘„åƒå¤´æ”¯æŒã€å®æ—¶ç›‘æ§ã€å¢å¼ºæ—¥å¿—ç­‰")

    sys.exit(app.exec())


if __name__ == "__main__":
    main()